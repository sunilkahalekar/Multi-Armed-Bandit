{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Thompson Sampling.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTVrgCngv7Pz"
      },
      "source": [
        "###Thompson Sampling\n",
        "\n",
        "The Thompson Sampling algorithm utilises a Bayesian probabilistic approach to modelling the reward distribution of the various arms.\n",
        "\n",
        "A Beta distribution for each arm based on its prior parameters and its playthrough history. At each trial iteration, we will randomly sample from the posterior Beta distribution of each arm, and choose the arm which gives the max value for the next round. This allows the Thompson Sampling to balance between exploration and exploitation based on the individual posterior Beta distributions of each arm. Arms that are not explored as often as others will definitely have a wider variance, which creates opportunities for it to be picked based on stochastic sampling.\n",
        "\n",
        "After selection of the best arm, we will play it and update the playthrough history of that arm (counts of attempts and successful reward). Note that each successful reward count will increase a_posterior while each unsuccessful reward count will increase b_posterior."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lF1kc_D9v72l"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import altair as alt\n",
        "from scipy.stats import beta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARtfFxZvwl6O"
      },
      "source": [
        "class BernoulliArm():\n",
        "    def __init__(self, p):\n",
        "        self.p = p\n",
        "    \n",
        "    # Reward system based on Bernoulli\n",
        "    def draw(self):\n",
        "        if random.random() > self.p:\n",
        "            return 0.0\n",
        "        else:\n",
        "            return 1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brLpk9_vwou6"
      },
      "source": [
        "def simulation_algorithm(algo, arms, num_sims, horizon):\n",
        "    \n",
        "    # Initialise variables for duration of accumulated simulation (num_sims * horizon_per_simulation)\n",
        "    chosen_arms = [0.0 for i in range(num_sims * horizon)]\n",
        "    rewards = [0.0 for i in range(num_sims * horizon)]\n",
        "    cumulative_rewards = [0 for i in range(num_sims * horizon)]\n",
        "    sim_nums = [0.0 for i in range(num_sims *horizon)]\n",
        "    times = [0.0 for i in range (num_sims*horizon)]\n",
        "    \n",
        "    for sim in range(num_sims):\n",
        "        sim = sim + 1\n",
        "        algo.initialize(len(arms))\n",
        "        \n",
        "        for t in range(horizon):\n",
        "            t = t + 1\n",
        "            index = (sim -1) * horizon + t -1\n",
        "            sim_nums[index] = sim\n",
        "            times[index] = t\n",
        "            \n",
        "            # Selection of best arm and engaging it\n",
        "            chosen_arm = algo.select_arm()\n",
        "            chosen_arms[index] = chosen_arm\n",
        "            \n",
        "            # Engage chosen Bernoulli Arm and obtain reward info\n",
        "            reward = arms[chosen_arm].draw()\n",
        "            rewards[index] = reward\n",
        "            \n",
        "            if t ==1:\n",
        "                cumulative_rewards[index] = reward\n",
        "            else:\n",
        "                cumulative_rewards[index] = cumulative_rewards[index-1] + reward\n",
        "                \n",
        "            algo.update(chosen_arm, reward)\n",
        "    \n",
        "    return [sim_nums, times, chosen_arms, rewards, cumulative_rewards]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEJJynkUwDkK"
      },
      "source": [
        "class ThompsonSampling():\n",
        "    def __init__(self, counts, values, a, b):\n",
        "        self.counts = counts\n",
        "        self.values = values\n",
        "        \n",
        "        # Beta parameters\n",
        "        self.a = a\n",
        "        self.b = b\n",
        "        return\n",
        "\n",
        "    def initialize(self, n_arms):\n",
        "        self.counts = [0 for col in range(n_arms)]\n",
        "        self.values = [0.0 for col in range(n_arms)]\n",
        "\n",
        "        # Uniform distribution of prior beta (A,B)\n",
        "        self.a = [1 for arm in range(n_arms)]\n",
        "        self.b = [1 for arm in range(n_arms)]\n",
        "        return\n",
        "    \n",
        "    def select_arm(self):\n",
        "        n_arms = len(self.counts)\n",
        "        \n",
        "        # Pair up all beta params of a and b for each arm\n",
        "        beta_params = zip(self.a, self.b)\n",
        "        \n",
        "        # Perform random draw for all arms based on their params (a,b)\n",
        "        all_draws = [beta.rvs(i[0], i[1], size = 1) for i in beta_params]\n",
        "        \n",
        "        # return index of arm with the highest draw\n",
        "        return all_draws.index(max(all_draws))\n",
        "    \n",
        "    def update(self, chosen_arm, reward):\n",
        "        self.counts[chosen_arm] = self.counts[chosen_arm] + 1\n",
        "        n = self.counts[chosen_arm]\n",
        "        \n",
        "        value = self.values[chosen_arm]\n",
        "        new_value = ((n - 1) / float(n)) * value + (1 / float(n)) * reward\n",
        "        self.values[chosen_arm] = new_value\n",
        "        \n",
        "        # Update a and b\n",
        "        \n",
        "        # a is based on total counts of rewards of arm\n",
        "        self.a[chosen_arm] = self.a[chosen_arm] + reward\n",
        "        \n",
        "        # b is based on total counts of failed rewards on arm\n",
        "        self.b[chosen_arm] = self.b[chosen_arm] + (1-reward)\n",
        "        \n",
        "        return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5E2wBgEwHgF",
        "outputId": "4b3accce-76d1-4e42-cde1-7fdeb2a56b76"
      },
      "source": [
        "import random\n",
        "\n",
        "random.seed(1)\n",
        "# out of 5 arms, 1 arm is clearly the best\n",
        "means = [0.4, 0.3, 0.5, 0.2, 0.1]\n",
        "n_arms = len(means)\n",
        "# Shuffling arms\n",
        "#random.shuffle(means)\n",
        "\n",
        "# Create list of Bernoulli Arms with Reward Information\n",
        "arms = list(map(lambda mu: BernoulliArm(mu), means))\n",
        "print(\"Best arm is \" + str(np.argmax(means)))\n",
        "\n",
        "f = open(\"ts_results.tsv\", \"w+\")\n",
        "\n",
        "# Create simulations for ThompsonSampling\n",
        "algo = ThompsonSampling([], [], [], [])\n",
        "algo.initialize(n_arms)\n",
        "results = simulation_algorithm(algo, arms, 5000, 250)\n",
        "    \n",
        "# Store data\n",
        "for i in range(len(results[0])):\n",
        "    f.write(\"\\t\".join([str(results[j][i]) for j in range(len(results))]) + \"\\n\")\n",
        "f.close()\n",
        "print(\"Simulation done using Thompson Sampling, you can check result now\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best arm is 2\n",
            "Simulation done using Thompson Sampling, you can check result now\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "8rM0ZbILwOi2",
        "outputId": "ac58d818-0a68-482b-b100-65d121f25ab0"
      },
      "source": [
        "df = pd.read_csv(\"/content/ts_results.tsv\", sep = \"\\t\", header = None, names = [\"simulation_num\", \"step\", \"chosen_arm\", \"reward\", \"cum_reward\"])\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>simulation_num</th>\n",
              "      <th>step</th>\n",
              "      <th>chosen_arm</th>\n",
              "      <th>reward</th>\n",
              "      <th>cum_reward</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   simulation_num  step  chosen_arm  reward  cum_reward\n",
              "0               1     1           2     1.0         1.0\n",
              "1               1     2           2     0.0         1.0\n",
              "2               1     3           4     0.0         1.0\n",
              "3               1     4           3     0.0         1.0\n",
              "4               1     5           4     0.0         1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zY_TnlTdw9ff"
      },
      "source": [
        "# Create a flag for each step to see if best arm was chosen\n",
        "df[\"chose_correct\"] = np.select(\n",
        "    [\n",
        "        df[\"chosen_arm\"] == 2,\n",
        "        df[\"chosen_arm\"] != 2\n",
        "    ],\n",
        "    [\n",
        "        1,\n",
        "        0\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "xirzjNbNxCu_",
        "outputId": "c84e2c0f-5822-451f-c9e2-6ab24c4a8501"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist(df[\"chosen_arm\"])\n",
        "plt.title('Histogram of Arm selections')\n",
        "plt.xlabel('Arms')\n",
        "plt.ylabel('Number of times each Arm was selected')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFgsO3SZxJoX"
      },
      "source": [
        "# Perform average/mean for each step for all simulations and epsilon\n",
        "df_chose_correctly = df.loc[:,[\"step\", \"chose_correct\"]].groupby([\"step\"]).agg(\"mean\")\n",
        "\n",
        "# Remove multi index grouping\n",
        "df_chose_correctly = df_chose_correctly.reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "dJnSY2KyxMpl",
        "outputId": "766afcaf-3275-455e-d254-aa3d3cd106dc"
      },
      "source": [
        "alt.Chart(df_chose_correctly).mark_line().encode(\n",
        "    alt.X(\"step:Q\", title = \"Time Step\"),\n",
        "    alt.Y(\"chose_correct:Q\", title = \"Mean Rate of Choosing Best Arm\", scale = alt.Scale(domain = [0, 1])),\n",
        ").properties(\n",
        "    title = \"TS: Mean Rate of Choosing Best Arm from 5000 Simulations. 5 Arms = [0.4,0.3, 0.5,0.2, 0.1]\",\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "alt.Chart(...)"
            ],
            "text/html": [
              "\n",
              "<div id=\"altair-viz-19466087c1b343379502883eaebe1a57\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "  (function(spec, embedOpt){\n",
              "    let outputDiv = document.currentScript.previousElementSibling;\n",
              "    if (outputDiv.id !== \"altair-viz-19466087c1b343379502883eaebe1a57\") {\n",
              "      outputDiv = document.getElementById(\"altair-viz-19466087c1b343379502883eaebe1a57\");\n",
              "    }\n",
              "    const paths = {\n",
              "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
              "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
              "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
              "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
              "    };\n",
              "\n",
              "    function loadScript(lib) {\n",
              "      return new Promise(function(resolve, reject) {\n",
              "        var s = document.createElement('script');\n",
              "        s.src = paths[lib];\n",
              "        s.async = true;\n",
              "        s.onload = () => resolve(paths[lib]);\n",
              "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
              "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "      });\n",
              "    }\n",
              "\n",
              "    function showError(err) {\n",
              "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
              "      throw err;\n",
              "    }\n",
              "\n",
              "    function displayChart(vegaEmbed) {\n",
              "      vegaEmbed(outputDiv, spec, embedOpt)\n",
              "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
              "    }\n",
              "\n",
              "    if(typeof define === \"function\" && define.amd) {\n",
              "      requirejs.config({paths});\n",
              "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
              "    } else if (typeof vegaEmbed === \"function\") {\n",
              "      displayChart(vegaEmbed);\n",
              "    } else {\n",
              "      loadScript(\"vega\")\n",
              "        .then(() => loadScript(\"vega-lite\"))\n",
              "        .then(() => loadScript(\"vega-embed\"))\n",
              "        .catch(showError)\n",
              "        .then(() => displayChart(vegaEmbed));\n",
              "    }\n",
              "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-1511f94cd3203ac5335ebb7b3e7fb440\"}, \"mark\": \"line\", \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"step\", \"title\": \"Time Step\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"chose_correct\", \"scale\": {\"domain\": [0, 1]}, \"title\": \"Mean Rate of Choosing Best Arm\"}}, \"title\": \"TS: Mean Rate of Choosing Best Arm from 5000 Simulations. 5 Arms = [0.4,0.3, 0.5,0.2, 0.1]\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-1511f94cd3203ac5335ebb7b3e7fb440\": [{\"step\": 1, \"chose_correct\": 0.2}, {\"step\": 2, \"chose_correct\": 0.2036}, {\"step\": 3, \"chose_correct\": 0.2352}, {\"step\": 4, \"chose_correct\": 0.242}, {\"step\": 5, \"chose_correct\": 0.249}, {\"step\": 6, \"chose_correct\": 0.2586}, {\"step\": 7, \"chose_correct\": 0.2794}, {\"step\": 8, \"chose_correct\": 0.2784}, {\"step\": 9, \"chose_correct\": 0.2912}, {\"step\": 10, \"chose_correct\": 0.3002}, {\"step\": 11, \"chose_correct\": 0.2968}, {\"step\": 12, \"chose_correct\": 0.3064}, {\"step\": 13, \"chose_correct\": 0.315}, {\"step\": 14, \"chose_correct\": 0.315}, {\"step\": 15, \"chose_correct\": 0.3348}, {\"step\": 16, \"chose_correct\": 0.3342}, {\"step\": 17, \"chose_correct\": 0.3316}, {\"step\": 18, \"chose_correct\": 0.3322}, {\"step\": 19, \"chose_correct\": 0.3434}, {\"step\": 20, \"chose_correct\": 0.3458}, {\"step\": 21, \"chose_correct\": 0.3596}, {\"step\": 22, \"chose_correct\": 0.3592}, {\"step\": 23, \"chose_correct\": 0.3606}, {\"step\": 24, \"chose_correct\": 0.3626}, {\"step\": 25, \"chose_correct\": 0.3808}, {\"step\": 26, \"chose_correct\": 0.378}, {\"step\": 27, \"chose_correct\": 0.3868}, {\"step\": 28, \"chose_correct\": 0.389}, {\"step\": 29, \"chose_correct\": 0.4068}, {\"step\": 30, \"chose_correct\": 0.4048}, {\"step\": 31, \"chose_correct\": 0.4054}, {\"step\": 32, \"chose_correct\": 0.4034}, {\"step\": 33, \"chose_correct\": 0.4118}, {\"step\": 34, \"chose_correct\": 0.4098}, {\"step\": 35, \"chose_correct\": 0.4062}, {\"step\": 36, \"chose_correct\": 0.4098}, {\"step\": 37, \"chose_correct\": 0.4218}, {\"step\": 38, \"chose_correct\": 0.4394}, {\"step\": 39, \"chose_correct\": 0.4252}, {\"step\": 40, \"chose_correct\": 0.4366}, {\"step\": 41, \"chose_correct\": 0.4384}, {\"step\": 42, \"chose_correct\": 0.4486}, {\"step\": 43, \"chose_correct\": 0.437}, {\"step\": 44, \"chose_correct\": 0.4614}, {\"step\": 45, \"chose_correct\": 0.463}, {\"step\": 46, \"chose_correct\": 0.4502}, {\"step\": 47, \"chose_correct\": 0.4628}, {\"step\": 48, \"chose_correct\": 0.4722}, {\"step\": 49, \"chose_correct\": 0.4528}, {\"step\": 50, \"chose_correct\": 0.4704}, {\"step\": 51, \"chose_correct\": 0.4744}, {\"step\": 52, \"chose_correct\": 0.4788}, {\"step\": 53, \"chose_correct\": 0.4828}, {\"step\": 54, \"chose_correct\": 0.4724}, {\"step\": 55, \"chose_correct\": 0.4726}, {\"step\": 56, \"chose_correct\": 0.482}, {\"step\": 57, \"chose_correct\": 0.4924}, {\"step\": 58, \"chose_correct\": 0.4922}, {\"step\": 59, \"chose_correct\": 0.4994}, {\"step\": 60, \"chose_correct\": 0.4964}, {\"step\": 61, \"chose_correct\": 0.5108}, {\"step\": 62, \"chose_correct\": 0.5092}, {\"step\": 63, \"chose_correct\": 0.5118}, {\"step\": 64, \"chose_correct\": 0.502}, {\"step\": 65, \"chose_correct\": 0.5198}, {\"step\": 66, \"chose_correct\": 0.5062}, {\"step\": 67, \"chose_correct\": 0.507}, {\"step\": 68, \"chose_correct\": 0.5114}, {\"step\": 69, \"chose_correct\": 0.5296}, {\"step\": 70, \"chose_correct\": 0.5296}, {\"step\": 71, \"chose_correct\": 0.5244}, {\"step\": 72, \"chose_correct\": 0.5294}, {\"step\": 73, \"chose_correct\": 0.5328}, {\"step\": 74, \"chose_correct\": 0.5346}, {\"step\": 75, \"chose_correct\": 0.5398}, {\"step\": 76, \"chose_correct\": 0.5354}, {\"step\": 77, \"chose_correct\": 0.5456}, {\"step\": 78, \"chose_correct\": 0.5442}, {\"step\": 79, \"chose_correct\": 0.5326}, {\"step\": 80, \"chose_correct\": 0.547}, {\"step\": 81, \"chose_correct\": 0.5518}, {\"step\": 82, \"chose_correct\": 0.5554}, {\"step\": 83, \"chose_correct\": 0.5398}, {\"step\": 84, \"chose_correct\": 0.5496}, {\"step\": 85, \"chose_correct\": 0.5686}, {\"step\": 86, \"chose_correct\": 0.56}, {\"step\": 87, \"chose_correct\": 0.5632}, {\"step\": 88, \"chose_correct\": 0.5584}, {\"step\": 89, \"chose_correct\": 0.5628}, {\"step\": 90, \"chose_correct\": 0.5652}, {\"step\": 91, \"chose_correct\": 0.5668}, {\"step\": 92, \"chose_correct\": 0.5774}, {\"step\": 93, \"chose_correct\": 0.5722}, {\"step\": 94, \"chose_correct\": 0.5816}, {\"step\": 95, \"chose_correct\": 0.5688}, {\"step\": 96, \"chose_correct\": 0.5756}, {\"step\": 97, \"chose_correct\": 0.5836}, {\"step\": 98, \"chose_correct\": 0.5678}, {\"step\": 99, \"chose_correct\": 0.5916}, {\"step\": 100, \"chose_correct\": 0.5756}, {\"step\": 101, \"chose_correct\": 0.5912}, {\"step\": 102, \"chose_correct\": 0.5886}, {\"step\": 103, \"chose_correct\": 0.599}, {\"step\": 104, \"chose_correct\": 0.5984}, {\"step\": 105, \"chose_correct\": 0.5874}, {\"step\": 106, \"chose_correct\": 0.6016}, {\"step\": 107, \"chose_correct\": 0.6128}, {\"step\": 108, \"chose_correct\": 0.607}, {\"step\": 109, \"chose_correct\": 0.5968}, {\"step\": 110, \"chose_correct\": 0.6092}, {\"step\": 111, \"chose_correct\": 0.609}, {\"step\": 112, \"chose_correct\": 0.6268}, {\"step\": 113, \"chose_correct\": 0.6074}, {\"step\": 114, \"chose_correct\": 0.6146}, {\"step\": 115, \"chose_correct\": 0.6132}, {\"step\": 116, \"chose_correct\": 0.611}, {\"step\": 117, \"chose_correct\": 0.6074}, {\"step\": 118, \"chose_correct\": 0.615}, {\"step\": 119, \"chose_correct\": 0.6106}, {\"step\": 120, \"chose_correct\": 0.6238}, {\"step\": 121, \"chose_correct\": 0.6206}, {\"step\": 122, \"chose_correct\": 0.6262}, {\"step\": 123, \"chose_correct\": 0.6196}, {\"step\": 124, \"chose_correct\": 0.6244}, {\"step\": 125, \"chose_correct\": 0.618}, {\"step\": 126, \"chose_correct\": 0.6232}, {\"step\": 127, \"chose_correct\": 0.6294}, {\"step\": 128, \"chose_correct\": 0.6308}, {\"step\": 129, \"chose_correct\": 0.631}, {\"step\": 130, \"chose_correct\": 0.6344}, {\"step\": 131, \"chose_correct\": 0.6406}, {\"step\": 132, \"chose_correct\": 0.6446}, {\"step\": 133, \"chose_correct\": 0.6364}, {\"step\": 134, \"chose_correct\": 0.6478}, {\"step\": 135, \"chose_correct\": 0.6408}, {\"step\": 136, \"chose_correct\": 0.642}, {\"step\": 137, \"chose_correct\": 0.6522}, {\"step\": 138, \"chose_correct\": 0.6346}, {\"step\": 139, \"chose_correct\": 0.652}, {\"step\": 140, \"chose_correct\": 0.6454}, {\"step\": 141, \"chose_correct\": 0.6516}, {\"step\": 142, \"chose_correct\": 0.6516}, {\"step\": 143, \"chose_correct\": 0.6558}, {\"step\": 144, \"chose_correct\": 0.6684}, {\"step\": 145, \"chose_correct\": 0.6432}, {\"step\": 146, \"chose_correct\": 0.6572}, {\"step\": 147, \"chose_correct\": 0.649}, {\"step\": 148, \"chose_correct\": 0.6666}, {\"step\": 149, \"chose_correct\": 0.655}, {\"step\": 150, \"chose_correct\": 0.664}, {\"step\": 151, \"chose_correct\": 0.6602}, {\"step\": 152, \"chose_correct\": 0.6604}, {\"step\": 153, \"chose_correct\": 0.6674}, {\"step\": 154, \"chose_correct\": 0.6618}, {\"step\": 155, \"chose_correct\": 0.6696}, {\"step\": 156, \"chose_correct\": 0.671}, {\"step\": 157, \"chose_correct\": 0.6712}, {\"step\": 158, \"chose_correct\": 0.663}, {\"step\": 159, \"chose_correct\": 0.6754}, {\"step\": 160, \"chose_correct\": 0.6716}, {\"step\": 161, \"chose_correct\": 0.6646}, {\"step\": 162, \"chose_correct\": 0.6766}, {\"step\": 163, \"chose_correct\": 0.6792}, {\"step\": 164, \"chose_correct\": 0.6822}, {\"step\": 165, \"chose_correct\": 0.6906}, {\"step\": 166, \"chose_correct\": 0.686}, {\"step\": 167, \"chose_correct\": 0.6802}, {\"step\": 168, \"chose_correct\": 0.691}, {\"step\": 169, \"chose_correct\": 0.689}, {\"step\": 170, \"chose_correct\": 0.69}, {\"step\": 171, \"chose_correct\": 0.687}, {\"step\": 172, \"chose_correct\": 0.6832}, {\"step\": 173, \"chose_correct\": 0.6954}, {\"step\": 174, \"chose_correct\": 0.694}, {\"step\": 175, \"chose_correct\": 0.703}, {\"step\": 176, \"chose_correct\": 0.6978}, {\"step\": 177, \"chose_correct\": 0.7046}, {\"step\": 178, \"chose_correct\": 0.688}, {\"step\": 179, \"chose_correct\": 0.6908}, {\"step\": 180, \"chose_correct\": 0.695}, {\"step\": 181, \"chose_correct\": 0.6978}, {\"step\": 182, \"chose_correct\": 0.6986}, {\"step\": 183, \"chose_correct\": 0.6954}, {\"step\": 184, \"chose_correct\": 0.7108}, {\"step\": 185, \"chose_correct\": 0.7044}, {\"step\": 186, \"chose_correct\": 0.7076}, {\"step\": 187, \"chose_correct\": 0.7038}, {\"step\": 188, \"chose_correct\": 0.6988}, {\"step\": 189, \"chose_correct\": 0.7146}, {\"step\": 190, \"chose_correct\": 0.7054}, {\"step\": 191, \"chose_correct\": 0.6996}, {\"step\": 192, \"chose_correct\": 0.7024}, {\"step\": 193, \"chose_correct\": 0.7148}, {\"step\": 194, \"chose_correct\": 0.7072}, {\"step\": 195, \"chose_correct\": 0.7098}, {\"step\": 196, \"chose_correct\": 0.7202}, {\"step\": 197, \"chose_correct\": 0.7132}, {\"step\": 198, \"chose_correct\": 0.7286}, {\"step\": 199, \"chose_correct\": 0.715}, {\"step\": 200, \"chose_correct\": 0.7148}, {\"step\": 201, \"chose_correct\": 0.72}, {\"step\": 202, \"chose_correct\": 0.7264}, {\"step\": 203, \"chose_correct\": 0.716}, {\"step\": 204, \"chose_correct\": 0.7214}, {\"step\": 205, \"chose_correct\": 0.7252}, {\"step\": 206, \"chose_correct\": 0.7274}, {\"step\": 207, \"chose_correct\": 0.7196}, {\"step\": 208, \"chose_correct\": 0.7284}, {\"step\": 209, \"chose_correct\": 0.7236}, {\"step\": 210, \"chose_correct\": 0.7316}, {\"step\": 211, \"chose_correct\": 0.7312}, {\"step\": 212, \"chose_correct\": 0.722}, {\"step\": 213, \"chose_correct\": 0.7338}, {\"step\": 214, \"chose_correct\": 0.7334}, {\"step\": 215, \"chose_correct\": 0.7338}, {\"step\": 216, \"chose_correct\": 0.7352}, {\"step\": 217, \"chose_correct\": 0.729}, {\"step\": 218, \"chose_correct\": 0.7334}, {\"step\": 219, \"chose_correct\": 0.7408}, {\"step\": 220, \"chose_correct\": 0.7388}, {\"step\": 221, \"chose_correct\": 0.7324}, {\"step\": 222, \"chose_correct\": 0.7312}, {\"step\": 223, \"chose_correct\": 0.7492}, {\"step\": 224, \"chose_correct\": 0.74}, {\"step\": 225, \"chose_correct\": 0.7364}, {\"step\": 226, \"chose_correct\": 0.7456}, {\"step\": 227, \"chose_correct\": 0.7358}, {\"step\": 228, \"chose_correct\": 0.7472}, {\"step\": 229, \"chose_correct\": 0.7456}, {\"step\": 230, \"chose_correct\": 0.7358}, {\"step\": 231, \"chose_correct\": 0.7372}, {\"step\": 232, \"chose_correct\": 0.742}, {\"step\": 233, \"chose_correct\": 0.7454}, {\"step\": 234, \"chose_correct\": 0.7496}, {\"step\": 235, \"chose_correct\": 0.7504}, {\"step\": 236, \"chose_correct\": 0.7454}, {\"step\": 237, \"chose_correct\": 0.7552}, {\"step\": 238, \"chose_correct\": 0.7538}, {\"step\": 239, \"chose_correct\": 0.7586}, {\"step\": 240, \"chose_correct\": 0.749}, {\"step\": 241, \"chose_correct\": 0.7636}, {\"step\": 242, \"chose_correct\": 0.7548}, {\"step\": 243, \"chose_correct\": 0.7616}, {\"step\": 244, \"chose_correct\": 0.7556}, {\"step\": 245, \"chose_correct\": 0.7538}, {\"step\": 246, \"chose_correct\": 0.753}, {\"step\": 247, \"chose_correct\": 0.7592}, {\"step\": 248, \"chose_correct\": 0.7626}, {\"step\": 249, \"chose_correct\": 0.7624}, {\"step\": 250, \"chose_correct\": 0.7678}]}}, {\"mode\": \"vega-lite\"});\n",
              "</script>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvlLZyJyzEXb"
      },
      "source": [
        "The Thompson Sampling algorithm shows a relatively quick convergence to the choice of best arm. Within 60 trials, the average rate of choosing the best arm is around 78%. This is extremely impressive compared to the other algorithms we have seen so far.\n",
        "\n",
        "At the start, all arms are perceived equally since they all have the same priors. Thus, the rate of choosing the best arm always starts from 20%, which is a random chance of choosing the best arm out of 5 arms. As the trial progresses, the algorithm lets the playthrough history of the arms take over, and it quickly identifies the best arm with each update of the posterior Beta distribution. Note that the progression is also smooth as compared to what we observed in the UCB algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7443Tei1xQFl"
      },
      "source": [
        "df_cumreward = df.loc[:,[\"step\", \"cum_reward\"]].groupby([\"step\"]).agg(\"mean\").reset_index()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "KBtY2RCuxTUA",
        "outputId": "5743d21a-e0bf-47b9-8f2d-ac70d21b671c"
      },
      "source": [
        "alt.Chart(df_cumreward).mark_line().encode(\n",
        "    alt.X(\"step:Q\", title = \"Time Step\"),\n",
        "    alt.Y(\"cum_reward:Q\", title = \"Mean Cumulative Reward\")\n",
        ").properties(\n",
        "    title = \"TS: Mean Cumulative Reward from 5000 Simulations. 5 Arms = [0.4,0.3,0.5, 0.2,0.1]\",\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "alt.Chart(...)"
            ],
            "text/html": [
              "\n",
              "<div id=\"altair-viz-1aab2611f4dd4b1aaccb0405bffd1183\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "  (function(spec, embedOpt){\n",
              "    let outputDiv = document.currentScript.previousElementSibling;\n",
              "    if (outputDiv.id !== \"altair-viz-1aab2611f4dd4b1aaccb0405bffd1183\") {\n",
              "      outputDiv = document.getElementById(\"altair-viz-1aab2611f4dd4b1aaccb0405bffd1183\");\n",
              "    }\n",
              "    const paths = {\n",
              "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
              "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
              "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
              "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
              "    };\n",
              "\n",
              "    function loadScript(lib) {\n",
              "      return new Promise(function(resolve, reject) {\n",
              "        var s = document.createElement('script');\n",
              "        s.src = paths[lib];\n",
              "        s.async = true;\n",
              "        s.onload = () => resolve(paths[lib]);\n",
              "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
              "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "      });\n",
              "    }\n",
              "\n",
              "    function showError(err) {\n",
              "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
              "      throw err;\n",
              "    }\n",
              "\n",
              "    function displayChart(vegaEmbed) {\n",
              "      vegaEmbed(outputDiv, spec, embedOpt)\n",
              "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
              "    }\n",
              "\n",
              "    if(typeof define === \"function\" && define.amd) {\n",
              "      requirejs.config({paths});\n",
              "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
              "    } else if (typeof vegaEmbed === \"function\") {\n",
              "      displayChart(vegaEmbed);\n",
              "    } else {\n",
              "      loadScript(\"vega\")\n",
              "        .then(() => loadScript(\"vega-lite\"))\n",
              "        .then(() => loadScript(\"vega-embed\"))\n",
              "        .catch(showError)\n",
              "        .then(() => displayChart(vegaEmbed));\n",
              "    }\n",
              "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-bf540dd3f266d70009f2bf881c2238a5\"}, \"mark\": \"line\", \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"step\", \"title\": \"Time Step\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"cum_reward\", \"title\": \"Mean Cumulative Reward\"}}, \"title\": \"TS: Mean Cumulative Reward from 5000 Simulations. 5 Arms = [0.4,0.3,0.5, 0.2,0.1]\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-bf540dd3f266d70009f2bf881c2238a5\": [{\"step\": 1, \"cum_reward\": 0.301}, {\"step\": 2, \"cum_reward\": 0.6058}, {\"step\": 3, \"cum_reward\": 0.916}, {\"step\": 4, \"cum_reward\": 1.2458}, {\"step\": 5, \"cum_reward\": 1.552}, {\"step\": 6, \"cum_reward\": 1.879}, {\"step\": 7, \"cum_reward\": 2.2138}, {\"step\": 8, \"cum_reward\": 2.55}, {\"step\": 9, \"cum_reward\": 2.889}, {\"step\": 10, \"cum_reward\": 3.2252}, {\"step\": 11, \"cum_reward\": 3.5756}, {\"step\": 12, \"cum_reward\": 3.9256}, {\"step\": 13, \"cum_reward\": 4.2818}, {\"step\": 14, \"cum_reward\": 4.6276}, {\"step\": 15, \"cum_reward\": 4.9832}, {\"step\": 16, \"cum_reward\": 5.3392}, {\"step\": 17, \"cum_reward\": 5.6918}, {\"step\": 18, \"cum_reward\": 6.0574}, {\"step\": 19, \"cum_reward\": 6.4162}, {\"step\": 20, \"cum_reward\": 6.7764}, {\"step\": 21, \"cum_reward\": 7.148}, {\"step\": 22, \"cum_reward\": 7.514}, {\"step\": 23, \"cum_reward\": 7.8738}, {\"step\": 24, \"cum_reward\": 8.2466}, {\"step\": 25, \"cum_reward\": 8.633}, {\"step\": 26, \"cum_reward\": 9.0106}, {\"step\": 27, \"cum_reward\": 9.3898}, {\"step\": 28, \"cum_reward\": 9.7704}, {\"step\": 29, \"cum_reward\": 10.1418}, {\"step\": 30, \"cum_reward\": 10.5274}, {\"step\": 31, \"cum_reward\": 10.9048}, {\"step\": 32, \"cum_reward\": 11.2784}, {\"step\": 33, \"cum_reward\": 11.6568}, {\"step\": 34, \"cum_reward\": 12.0374}, {\"step\": 35, \"cum_reward\": 12.4144}, {\"step\": 36, \"cum_reward\": 12.7992}, {\"step\": 37, \"cum_reward\": 13.1878}, {\"step\": 38, \"cum_reward\": 13.5698}, {\"step\": 39, \"cum_reward\": 13.9586}, {\"step\": 40, \"cum_reward\": 14.3416}, {\"step\": 41, \"cum_reward\": 14.7364}, {\"step\": 42, \"cum_reward\": 15.128}, {\"step\": 43, \"cum_reward\": 15.5236}, {\"step\": 44, \"cum_reward\": 15.9162}, {\"step\": 45, \"cum_reward\": 16.3136}, {\"step\": 46, \"cum_reward\": 16.7038}, {\"step\": 47, \"cum_reward\": 17.1024}, {\"step\": 48, \"cum_reward\": 17.5056}, {\"step\": 49, \"cum_reward\": 17.8926}, {\"step\": 50, \"cum_reward\": 18.2842}, {\"step\": 51, \"cum_reward\": 18.6722}, {\"step\": 52, \"cum_reward\": 19.0686}, {\"step\": 53, \"cum_reward\": 19.4698}, {\"step\": 54, \"cum_reward\": 19.8576}, {\"step\": 55, \"cum_reward\": 20.2596}, {\"step\": 56, \"cum_reward\": 20.672}, {\"step\": 57, \"cum_reward\": 21.0776}, {\"step\": 58, \"cum_reward\": 21.4864}, {\"step\": 59, \"cum_reward\": 21.9066}, {\"step\": 60, \"cum_reward\": 22.3176}, {\"step\": 61, \"cum_reward\": 22.7328}, {\"step\": 62, \"cum_reward\": 23.1344}, {\"step\": 63, \"cum_reward\": 23.5512}, {\"step\": 64, \"cum_reward\": 23.962}, {\"step\": 65, \"cum_reward\": 24.3708}, {\"step\": 66, \"cum_reward\": 24.7756}, {\"step\": 67, \"cum_reward\": 25.1894}, {\"step\": 68, \"cum_reward\": 25.6008}, {\"step\": 69, \"cum_reward\": 26.014}, {\"step\": 70, \"cum_reward\": 26.4184}, {\"step\": 71, \"cum_reward\": 26.83}, {\"step\": 72, \"cum_reward\": 27.2572}, {\"step\": 73, \"cum_reward\": 27.6602}, {\"step\": 74, \"cum_reward\": 28.0766}, {\"step\": 75, \"cum_reward\": 28.492}, {\"step\": 76, \"cum_reward\": 28.915}, {\"step\": 77, \"cum_reward\": 29.335}, {\"step\": 78, \"cum_reward\": 29.761}, {\"step\": 79, \"cum_reward\": 30.1832}, {\"step\": 80, \"cum_reward\": 30.607}, {\"step\": 81, \"cum_reward\": 31.0372}, {\"step\": 82, \"cum_reward\": 31.4494}, {\"step\": 83, \"cum_reward\": 31.86}, {\"step\": 84, \"cum_reward\": 32.2832}, {\"step\": 85, \"cum_reward\": 32.7102}, {\"step\": 86, \"cum_reward\": 33.1354}, {\"step\": 87, \"cum_reward\": 33.5618}, {\"step\": 88, \"cum_reward\": 33.9834}, {\"step\": 89, \"cum_reward\": 34.407}, {\"step\": 90, \"cum_reward\": 34.8312}, {\"step\": 91, \"cum_reward\": 35.258}, {\"step\": 92, \"cum_reward\": 35.683}, {\"step\": 93, \"cum_reward\": 36.103}, {\"step\": 94, \"cum_reward\": 36.5248}, {\"step\": 95, \"cum_reward\": 36.951}, {\"step\": 96, \"cum_reward\": 37.3752}, {\"step\": 97, \"cum_reward\": 37.8036}, {\"step\": 98, \"cum_reward\": 38.231}, {\"step\": 99, \"cum_reward\": 38.6476}, {\"step\": 100, \"cum_reward\": 39.083}, {\"step\": 101, \"cum_reward\": 39.5258}, {\"step\": 102, \"cum_reward\": 39.9462}, {\"step\": 103, \"cum_reward\": 40.3834}, {\"step\": 104, \"cum_reward\": 40.8148}, {\"step\": 105, \"cum_reward\": 41.2506}, {\"step\": 106, \"cum_reward\": 41.687}, {\"step\": 107, \"cum_reward\": 42.125}, {\"step\": 108, \"cum_reward\": 42.5668}, {\"step\": 109, \"cum_reward\": 43.0}, {\"step\": 110, \"cum_reward\": 43.4394}, {\"step\": 111, \"cum_reward\": 43.871}, {\"step\": 112, \"cum_reward\": 44.307}, {\"step\": 113, \"cum_reward\": 44.7398}, {\"step\": 114, \"cum_reward\": 45.1762}, {\"step\": 115, \"cum_reward\": 45.6152}, {\"step\": 116, \"cum_reward\": 46.0366}, {\"step\": 117, \"cum_reward\": 46.4752}, {\"step\": 118, \"cum_reward\": 46.9062}, {\"step\": 119, \"cum_reward\": 47.3354}, {\"step\": 120, \"cum_reward\": 47.7732}, {\"step\": 121, \"cum_reward\": 48.2078}, {\"step\": 122, \"cum_reward\": 48.6508}, {\"step\": 123, \"cum_reward\": 49.083}, {\"step\": 124, \"cum_reward\": 49.5206}, {\"step\": 125, \"cum_reward\": 49.9526}, {\"step\": 126, \"cum_reward\": 50.3972}, {\"step\": 127, \"cum_reward\": 50.839}, {\"step\": 128, \"cum_reward\": 51.2836}, {\"step\": 129, \"cum_reward\": 51.7184}, {\"step\": 130, \"cum_reward\": 52.1558}, {\"step\": 131, \"cum_reward\": 52.6076}, {\"step\": 132, \"cum_reward\": 53.036}, {\"step\": 133, \"cum_reward\": 53.4714}, {\"step\": 134, \"cum_reward\": 53.915}, {\"step\": 135, \"cum_reward\": 54.3508}, {\"step\": 136, \"cum_reward\": 54.788}, {\"step\": 137, \"cum_reward\": 55.2328}, {\"step\": 138, \"cum_reward\": 55.6582}, {\"step\": 139, \"cum_reward\": 56.1028}, {\"step\": 140, \"cum_reward\": 56.551}, {\"step\": 141, \"cum_reward\": 56.9934}, {\"step\": 142, \"cum_reward\": 57.4314}, {\"step\": 143, \"cum_reward\": 57.8894}, {\"step\": 144, \"cum_reward\": 58.3284}, {\"step\": 145, \"cum_reward\": 58.7636}, {\"step\": 146, \"cum_reward\": 59.2082}, {\"step\": 147, \"cum_reward\": 59.6438}, {\"step\": 148, \"cum_reward\": 60.0886}, {\"step\": 149, \"cum_reward\": 60.52}, {\"step\": 150, \"cum_reward\": 60.9574}, {\"step\": 151, \"cum_reward\": 61.4072}, {\"step\": 152, \"cum_reward\": 61.8412}, {\"step\": 153, \"cum_reward\": 62.2814}, {\"step\": 154, \"cum_reward\": 62.7338}, {\"step\": 155, \"cum_reward\": 63.1808}, {\"step\": 156, \"cum_reward\": 63.6328}, {\"step\": 157, \"cum_reward\": 64.0894}, {\"step\": 158, \"cum_reward\": 64.532}, {\"step\": 159, \"cum_reward\": 64.9844}, {\"step\": 160, \"cum_reward\": 65.4338}, {\"step\": 161, \"cum_reward\": 65.8802}, {\"step\": 162, \"cum_reward\": 66.3196}, {\"step\": 163, \"cum_reward\": 66.7794}, {\"step\": 164, \"cum_reward\": 67.234}, {\"step\": 165, \"cum_reward\": 67.685}, {\"step\": 166, \"cum_reward\": 68.1192}, {\"step\": 167, \"cum_reward\": 68.577}, {\"step\": 168, \"cum_reward\": 69.0244}, {\"step\": 169, \"cum_reward\": 69.4812}, {\"step\": 170, \"cum_reward\": 69.9304}, {\"step\": 171, \"cum_reward\": 70.3806}, {\"step\": 172, \"cum_reward\": 70.8312}, {\"step\": 173, \"cum_reward\": 71.2796}, {\"step\": 174, \"cum_reward\": 71.7338}, {\"step\": 175, \"cum_reward\": 72.1814}, {\"step\": 176, \"cum_reward\": 72.6418}, {\"step\": 177, \"cum_reward\": 73.0822}, {\"step\": 178, \"cum_reward\": 73.5384}, {\"step\": 179, \"cum_reward\": 73.9884}, {\"step\": 180, \"cum_reward\": 74.433}, {\"step\": 181, \"cum_reward\": 74.8858}, {\"step\": 182, \"cum_reward\": 75.3292}, {\"step\": 183, \"cum_reward\": 75.7826}, {\"step\": 184, \"cum_reward\": 76.2452}, {\"step\": 185, \"cum_reward\": 76.6894}, {\"step\": 186, \"cum_reward\": 77.148}, {\"step\": 187, \"cum_reward\": 77.5996}, {\"step\": 188, \"cum_reward\": 78.0538}, {\"step\": 189, \"cum_reward\": 78.5028}, {\"step\": 190, \"cum_reward\": 78.965}, {\"step\": 191, \"cum_reward\": 79.4206}, {\"step\": 192, \"cum_reward\": 79.8716}, {\"step\": 193, \"cum_reward\": 80.3274}, {\"step\": 194, \"cum_reward\": 80.801}, {\"step\": 195, \"cum_reward\": 81.263}, {\"step\": 196, \"cum_reward\": 81.7226}, {\"step\": 197, \"cum_reward\": 82.1788}, {\"step\": 198, \"cum_reward\": 82.645}, {\"step\": 199, \"cum_reward\": 83.0928}, {\"step\": 200, \"cum_reward\": 83.5598}, {\"step\": 201, \"cum_reward\": 84.0084}, {\"step\": 202, \"cum_reward\": 84.4786}, {\"step\": 203, \"cum_reward\": 84.9314}, {\"step\": 204, \"cum_reward\": 85.3856}, {\"step\": 205, \"cum_reward\": 85.8486}, {\"step\": 206, \"cum_reward\": 86.3036}, {\"step\": 207, \"cum_reward\": 86.7712}, {\"step\": 208, \"cum_reward\": 87.2326}, {\"step\": 209, \"cum_reward\": 87.702}, {\"step\": 210, \"cum_reward\": 88.1626}, {\"step\": 211, \"cum_reward\": 88.6336}, {\"step\": 212, \"cum_reward\": 89.0786}, {\"step\": 213, \"cum_reward\": 89.546}, {\"step\": 214, \"cum_reward\": 89.9956}, {\"step\": 215, \"cum_reward\": 90.4556}, {\"step\": 216, \"cum_reward\": 90.9156}, {\"step\": 217, \"cum_reward\": 91.3708}, {\"step\": 218, \"cum_reward\": 91.8236}, {\"step\": 219, \"cum_reward\": 92.278}, {\"step\": 220, \"cum_reward\": 92.7462}, {\"step\": 221, \"cum_reward\": 93.2072}, {\"step\": 222, \"cum_reward\": 93.6662}, {\"step\": 223, \"cum_reward\": 94.1284}, {\"step\": 224, \"cum_reward\": 94.5842}, {\"step\": 225, \"cum_reward\": 95.0514}, {\"step\": 226, \"cum_reward\": 95.5148}, {\"step\": 227, \"cum_reward\": 95.9682}, {\"step\": 228, \"cum_reward\": 96.4282}, {\"step\": 229, \"cum_reward\": 96.8772}, {\"step\": 230, \"cum_reward\": 97.3334}, {\"step\": 231, \"cum_reward\": 97.796}, {\"step\": 232, \"cum_reward\": 98.2584}, {\"step\": 233, \"cum_reward\": 98.7298}, {\"step\": 234, \"cum_reward\": 99.1896}, {\"step\": 235, \"cum_reward\": 99.6548}, {\"step\": 236, \"cum_reward\": 100.1216}, {\"step\": 237, \"cum_reward\": 100.5854}, {\"step\": 238, \"cum_reward\": 101.0596}, {\"step\": 239, \"cum_reward\": 101.5364}, {\"step\": 240, \"cum_reward\": 102.0088}, {\"step\": 241, \"cum_reward\": 102.4734}, {\"step\": 242, \"cum_reward\": 102.929}, {\"step\": 243, \"cum_reward\": 103.3936}, {\"step\": 244, \"cum_reward\": 103.8614}, {\"step\": 245, \"cum_reward\": 104.3344}, {\"step\": 246, \"cum_reward\": 104.7912}, {\"step\": 247, \"cum_reward\": 105.2466}, {\"step\": 248, \"cum_reward\": 105.705}, {\"step\": 249, \"cum_reward\": 106.1638}, {\"step\": 250, \"cum_reward\": 106.6264}]}}, {\"mode\": \"vega-lite\"});\n",
              "</script>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDu3rqC51JPw"
      },
      "source": [
        "Thompson Sampling algorithm manages to identify the choice of best arm early on, it starts accumulating rewards quickly. By the end of the time horizon of 250 steps, it reaches about 105 cumulative points on average, which means it outpeforms almost all the other algorithms such as Epsilon Greedy, UCB."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LR3GnD5txYQc"
      },
      "source": [
        "df_cumreward[\"best_cumreward\"] = df[\"step\"] * max(means)\n",
        "df_cumreward[\"regret\"] = df_cumreward[\"best_cumreward\"]-  df_cumreward[\"cum_reward\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "9iAJiT10xZMy",
        "outputId": "65d03647-4551-46d3-cbc8-6c61de494538"
      },
      "source": [
        "alt.Chart(df_cumreward).mark_line().encode(\n",
        "    alt.X(\"step:Q\", title = \"Time Step\"),\n",
        "    alt.Y(\"regret:Q\", title = \"Mean Cumulative Regret\")\n",
        ").properties(\n",
        "    title = \"TS: Mean Cumulative Regret from 5000 Simulations. 5 Arms = [0.4,0.3,0.5,0.2,0.1]\",\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "alt.Chart(...)"
            ],
            "text/html": [
              "\n",
              "<div id=\"altair-viz-b85d1f6b157240de963192ee24f5d71b\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "  (function(spec, embedOpt){\n",
              "    let outputDiv = document.currentScript.previousElementSibling;\n",
              "    if (outputDiv.id !== \"altair-viz-b85d1f6b157240de963192ee24f5d71b\") {\n",
              "      outputDiv = document.getElementById(\"altair-viz-b85d1f6b157240de963192ee24f5d71b\");\n",
              "    }\n",
              "    const paths = {\n",
              "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
              "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
              "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
              "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
              "    };\n",
              "\n",
              "    function loadScript(lib) {\n",
              "      return new Promise(function(resolve, reject) {\n",
              "        var s = document.createElement('script');\n",
              "        s.src = paths[lib];\n",
              "        s.async = true;\n",
              "        s.onload = () => resolve(paths[lib]);\n",
              "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
              "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "      });\n",
              "    }\n",
              "\n",
              "    function showError(err) {\n",
              "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
              "      throw err;\n",
              "    }\n",
              "\n",
              "    function displayChart(vegaEmbed) {\n",
              "      vegaEmbed(outputDiv, spec, embedOpt)\n",
              "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
              "    }\n",
              "\n",
              "    if(typeof define === \"function\" && define.amd) {\n",
              "      requirejs.config({paths});\n",
              "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
              "    } else if (typeof vegaEmbed === \"function\") {\n",
              "      displayChart(vegaEmbed);\n",
              "    } else {\n",
              "      loadScript(\"vega\")\n",
              "        .then(() => loadScript(\"vega-lite\"))\n",
              "        .then(() => loadScript(\"vega-embed\"))\n",
              "        .catch(showError)\n",
              "        .then(() => displayChart(vegaEmbed));\n",
              "    }\n",
              "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-2701aa6d91020cf512ed26eade62d7b5\"}, \"mark\": \"line\", \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"step\", \"title\": \"Time Step\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"regret\", \"title\": \"Mean Cumulative Regret\"}}, \"title\": \"TS: Mean Cumulative Regret from 5000 Simulations. 5 Arms = [0.4,0.3,0.5,0.2,0.1]\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-2701aa6d91020cf512ed26eade62d7b5\": [{\"step\": 1, \"cum_reward\": 0.301, \"best_cumreward\": 0.5, \"regret\": 0.199}, {\"step\": 2, \"cum_reward\": 0.6058, \"best_cumreward\": 1.0, \"regret\": 0.3942}, {\"step\": 3, \"cum_reward\": 0.916, \"best_cumreward\": 1.5, \"regret\": 0.584}, {\"step\": 4, \"cum_reward\": 1.2458, \"best_cumreward\": 2.0, \"regret\": 0.7542}, {\"step\": 5, \"cum_reward\": 1.552, \"best_cumreward\": 2.5, \"regret\": 0.948}, {\"step\": 6, \"cum_reward\": 1.879, \"best_cumreward\": 3.0, \"regret\": 1.121}, {\"step\": 7, \"cum_reward\": 2.2138, \"best_cumreward\": 3.5, \"regret\": 1.2862}, {\"step\": 8, \"cum_reward\": 2.55, \"best_cumreward\": 4.0, \"regret\": 1.4500000000000002}, {\"step\": 9, \"cum_reward\": 2.889, \"best_cumreward\": 4.5, \"regret\": 1.6110000000000002}, {\"step\": 10, \"cum_reward\": 3.2252, \"best_cumreward\": 5.0, \"regret\": 1.7748}, {\"step\": 11, \"cum_reward\": 3.5756, \"best_cumreward\": 5.5, \"regret\": 1.9243999999999999}, {\"step\": 12, \"cum_reward\": 3.9256, \"best_cumreward\": 6.0, \"regret\": 2.0744}, {\"step\": 13, \"cum_reward\": 4.2818, \"best_cumreward\": 6.5, \"regret\": 2.2182000000000004}, {\"step\": 14, \"cum_reward\": 4.6276, \"best_cumreward\": 7.0, \"regret\": 2.3724}, {\"step\": 15, \"cum_reward\": 4.9832, \"best_cumreward\": 7.5, \"regret\": 2.5168}, {\"step\": 16, \"cum_reward\": 5.3392, \"best_cumreward\": 8.0, \"regret\": 2.6608}, {\"step\": 17, \"cum_reward\": 5.6918, \"best_cumreward\": 8.5, \"regret\": 2.8082000000000003}, {\"step\": 18, \"cum_reward\": 6.0574, \"best_cumreward\": 9.0, \"regret\": 2.9425999999999997}, {\"step\": 19, \"cum_reward\": 6.4162, \"best_cumreward\": 9.5, \"regret\": 3.0838}, {\"step\": 20, \"cum_reward\": 6.7764, \"best_cumreward\": 10.0, \"regret\": 3.2236000000000002}, {\"step\": 21, \"cum_reward\": 7.148, \"best_cumreward\": 10.5, \"regret\": 3.3520000000000003}, {\"step\": 22, \"cum_reward\": 7.514, \"best_cumreward\": 11.0, \"regret\": 3.4859999999999998}, {\"step\": 23, \"cum_reward\": 7.8738, \"best_cumreward\": 11.5, \"regret\": 3.6262}, {\"step\": 24, \"cum_reward\": 8.2466, \"best_cumreward\": 12.0, \"regret\": 3.753399999999999}, {\"step\": 25, \"cum_reward\": 8.633, \"best_cumreward\": 12.5, \"regret\": 3.867000000000001}, {\"step\": 26, \"cum_reward\": 9.0106, \"best_cumreward\": 13.0, \"regret\": 3.9894}, {\"step\": 27, \"cum_reward\": 9.3898, \"best_cumreward\": 13.5, \"regret\": 4.110200000000001}, {\"step\": 28, \"cum_reward\": 9.7704, \"best_cumreward\": 14.0, \"regret\": 4.2296}, {\"step\": 29, \"cum_reward\": 10.1418, \"best_cumreward\": 14.5, \"regret\": 4.3582}, {\"step\": 30, \"cum_reward\": 10.5274, \"best_cumreward\": 15.0, \"regret\": 4.4726}, {\"step\": 31, \"cum_reward\": 10.9048, \"best_cumreward\": 15.5, \"regret\": 4.5952}, {\"step\": 32, \"cum_reward\": 11.2784, \"best_cumreward\": 16.0, \"regret\": 4.7216000000000005}, {\"step\": 33, \"cum_reward\": 11.6568, \"best_cumreward\": 16.5, \"regret\": 4.8431999999999995}, {\"step\": 34, \"cum_reward\": 12.0374, \"best_cumreward\": 17.0, \"regret\": 4.9626}, {\"step\": 35, \"cum_reward\": 12.4144, \"best_cumreward\": 17.5, \"regret\": 5.0855999999999995}, {\"step\": 36, \"cum_reward\": 12.7992, \"best_cumreward\": 18.0, \"regret\": 5.200799999999999}, {\"step\": 37, \"cum_reward\": 13.1878, \"best_cumreward\": 18.5, \"regret\": 5.312200000000001}, {\"step\": 38, \"cum_reward\": 13.5698, \"best_cumreward\": 19.0, \"regret\": 5.430199999999999}, {\"step\": 39, \"cum_reward\": 13.9586, \"best_cumreward\": 19.5, \"regret\": 5.541399999999999}, {\"step\": 40, \"cum_reward\": 14.3416, \"best_cumreward\": 20.0, \"regret\": 5.6584}, {\"step\": 41, \"cum_reward\": 14.7364, \"best_cumreward\": 20.5, \"regret\": 5.7636}, {\"step\": 42, \"cum_reward\": 15.128, \"best_cumreward\": 21.0, \"regret\": 5.872}, {\"step\": 43, \"cum_reward\": 15.5236, \"best_cumreward\": 21.5, \"regret\": 5.9764}, {\"step\": 44, \"cum_reward\": 15.9162, \"best_cumreward\": 22.0, \"regret\": 6.0838}, {\"step\": 45, \"cum_reward\": 16.3136, \"best_cumreward\": 22.5, \"regret\": 6.186399999999999}, {\"step\": 46, \"cum_reward\": 16.7038, \"best_cumreward\": 23.0, \"regret\": 6.296199999999999}, {\"step\": 47, \"cum_reward\": 17.1024, \"best_cumreward\": 23.5, \"regret\": 6.397600000000001}, {\"step\": 48, \"cum_reward\": 17.5056, \"best_cumreward\": 24.0, \"regret\": 6.494399999999999}, {\"step\": 49, \"cum_reward\": 17.8926, \"best_cumreward\": 24.5, \"regret\": 6.607399999999998}, {\"step\": 50, \"cum_reward\": 18.2842, \"best_cumreward\": 25.0, \"regret\": 6.7158000000000015}, {\"step\": 51, \"cum_reward\": 18.6722, \"best_cumreward\": 25.5, \"regret\": 6.8278}, {\"step\": 52, \"cum_reward\": 19.0686, \"best_cumreward\": 26.0, \"regret\": 6.9314}, {\"step\": 53, \"cum_reward\": 19.4698, \"best_cumreward\": 26.5, \"regret\": 7.030200000000001}, {\"step\": 54, \"cum_reward\": 19.8576, \"best_cumreward\": 27.0, \"regret\": 7.1423999999999985}, {\"step\": 55, \"cum_reward\": 20.2596, \"best_cumreward\": 27.5, \"regret\": 7.240400000000001}, {\"step\": 56, \"cum_reward\": 20.672, \"best_cumreward\": 28.0, \"regret\": 7.327999999999999}, {\"step\": 57, \"cum_reward\": 21.0776, \"best_cumreward\": 28.5, \"regret\": 7.4224}, {\"step\": 58, \"cum_reward\": 21.4864, \"best_cumreward\": 29.0, \"regret\": 7.5136}, {\"step\": 59, \"cum_reward\": 21.9066, \"best_cumreward\": 29.5, \"regret\": 7.593399999999999}, {\"step\": 60, \"cum_reward\": 22.3176, \"best_cumreward\": 30.0, \"regret\": 7.682400000000001}, {\"step\": 61, \"cum_reward\": 22.7328, \"best_cumreward\": 30.5, \"regret\": 7.767199999999999}, {\"step\": 62, \"cum_reward\": 23.1344, \"best_cumreward\": 31.0, \"regret\": 7.865600000000001}, {\"step\": 63, \"cum_reward\": 23.5512, \"best_cumreward\": 31.5, \"regret\": 7.9487999999999985}, {\"step\": 64, \"cum_reward\": 23.962, \"best_cumreward\": 32.0, \"regret\": 8.038}, {\"step\": 65, \"cum_reward\": 24.3708, \"best_cumreward\": 32.5, \"regret\": 8.1292}, {\"step\": 66, \"cum_reward\": 24.7756, \"best_cumreward\": 33.0, \"regret\": 8.2244}, {\"step\": 67, \"cum_reward\": 25.1894, \"best_cumreward\": 33.5, \"regret\": 8.3106}, {\"step\": 68, \"cum_reward\": 25.6008, \"best_cumreward\": 34.0, \"regret\": 8.3992}, {\"step\": 69, \"cum_reward\": 26.014, \"best_cumreward\": 34.5, \"regret\": 8.486}, {\"step\": 70, \"cum_reward\": 26.4184, \"best_cumreward\": 35.0, \"regret\": 8.581600000000002}, {\"step\": 71, \"cum_reward\": 26.83, \"best_cumreward\": 35.5, \"regret\": 8.670000000000002}, {\"step\": 72, \"cum_reward\": 27.2572, \"best_cumreward\": 36.0, \"regret\": 8.742799999999999}, {\"step\": 73, \"cum_reward\": 27.6602, \"best_cumreward\": 36.5, \"regret\": 8.8398}, {\"step\": 74, \"cum_reward\": 28.0766, \"best_cumreward\": 37.0, \"regret\": 8.9234}, {\"step\": 75, \"cum_reward\": 28.492, \"best_cumreward\": 37.5, \"regret\": 9.008}, {\"step\": 76, \"cum_reward\": 28.915, \"best_cumreward\": 38.0, \"regret\": 9.085}, {\"step\": 77, \"cum_reward\": 29.335, \"best_cumreward\": 38.5, \"regret\": 9.165}, {\"step\": 78, \"cum_reward\": 29.761, \"best_cumreward\": 39.0, \"regret\": 9.239}, {\"step\": 79, \"cum_reward\": 30.1832, \"best_cumreward\": 39.5, \"regret\": 9.3168}, {\"step\": 80, \"cum_reward\": 30.607, \"best_cumreward\": 40.0, \"regret\": 9.393}, {\"step\": 81, \"cum_reward\": 31.0372, \"best_cumreward\": 40.5, \"regret\": 9.462800000000001}, {\"step\": 82, \"cum_reward\": 31.4494, \"best_cumreward\": 41.0, \"regret\": 9.5506}, {\"step\": 83, \"cum_reward\": 31.86, \"best_cumreward\": 41.5, \"regret\": 9.64}, {\"step\": 84, \"cum_reward\": 32.2832, \"best_cumreward\": 42.0, \"regret\": 9.7168}, {\"step\": 85, \"cum_reward\": 32.7102, \"best_cumreward\": 42.5, \"regret\": 9.7898}, {\"step\": 86, \"cum_reward\": 33.1354, \"best_cumreward\": 43.0, \"regret\": 9.864600000000003}, {\"step\": 87, \"cum_reward\": 33.5618, \"best_cumreward\": 43.5, \"regret\": 9.938200000000002}, {\"step\": 88, \"cum_reward\": 33.9834, \"best_cumreward\": 44.0, \"regret\": 10.016599999999997}, {\"step\": 89, \"cum_reward\": 34.407, \"best_cumreward\": 44.5, \"regret\": 10.093000000000004}, {\"step\": 90, \"cum_reward\": 34.8312, \"best_cumreward\": 45.0, \"regret\": 10.168799999999997}, {\"step\": 91, \"cum_reward\": 35.258, \"best_cumreward\": 45.5, \"regret\": 10.241999999999997}, {\"step\": 92, \"cum_reward\": 35.683, \"best_cumreward\": 46.0, \"regret\": 10.317}, {\"step\": 93, \"cum_reward\": 36.103, \"best_cumreward\": 46.5, \"regret\": 10.396999999999998}, {\"step\": 94, \"cum_reward\": 36.5248, \"best_cumreward\": 47.0, \"regret\": 10.475200000000001}, {\"step\": 95, \"cum_reward\": 36.951, \"best_cumreward\": 47.5, \"regret\": 10.549}, {\"step\": 96, \"cum_reward\": 37.3752, \"best_cumreward\": 48.0, \"regret\": 10.6248}, {\"step\": 97, \"cum_reward\": 37.8036, \"best_cumreward\": 48.5, \"regret\": 10.696399999999997}, {\"step\": 98, \"cum_reward\": 38.231, \"best_cumreward\": 49.0, \"regret\": 10.768999999999998}, {\"step\": 99, \"cum_reward\": 38.6476, \"best_cumreward\": 49.5, \"regret\": 10.852400000000003}, {\"step\": 100, \"cum_reward\": 39.083, \"best_cumreward\": 50.0, \"regret\": 10.917000000000002}, {\"step\": 101, \"cum_reward\": 39.5258, \"best_cumreward\": 50.5, \"regret\": 10.974200000000003}, {\"step\": 102, \"cum_reward\": 39.9462, \"best_cumreward\": 51.0, \"regret\": 11.053800000000003}, {\"step\": 103, \"cum_reward\": 40.3834, \"best_cumreward\": 51.5, \"regret\": 11.116599999999998}, {\"step\": 104, \"cum_reward\": 40.8148, \"best_cumreward\": 52.0, \"regret\": 11.185200000000002}, {\"step\": 105, \"cum_reward\": 41.2506, \"best_cumreward\": 52.5, \"regret\": 11.249400000000001}, {\"step\": 106, \"cum_reward\": 41.687, \"best_cumreward\": 53.0, \"regret\": 11.313000000000002}, {\"step\": 107, \"cum_reward\": 42.125, \"best_cumreward\": 53.5, \"regret\": 11.375}, {\"step\": 108, \"cum_reward\": 42.5668, \"best_cumreward\": 54.0, \"regret\": 11.4332}, {\"step\": 109, \"cum_reward\": 43.0, \"best_cumreward\": 54.5, \"regret\": 11.5}, {\"step\": 110, \"cum_reward\": 43.4394, \"best_cumreward\": 55.0, \"regret\": 11.5606}, {\"step\": 111, \"cum_reward\": 43.871, \"best_cumreward\": 55.5, \"regret\": 11.628999999999998}, {\"step\": 112, \"cum_reward\": 44.307, \"best_cumreward\": 56.0, \"regret\": 11.692999999999998}, {\"step\": 113, \"cum_reward\": 44.7398, \"best_cumreward\": 56.5, \"regret\": 11.760199999999998}, {\"step\": 114, \"cum_reward\": 45.1762, \"best_cumreward\": 57.0, \"regret\": 11.823799999999999}, {\"step\": 115, \"cum_reward\": 45.6152, \"best_cumreward\": 57.5, \"regret\": 11.884799999999998}, {\"step\": 116, \"cum_reward\": 46.0366, \"best_cumreward\": 58.0, \"regret\": 11.9634}, {\"step\": 117, \"cum_reward\": 46.4752, \"best_cumreward\": 58.5, \"regret\": 12.024799999999999}, {\"step\": 118, \"cum_reward\": 46.9062, \"best_cumreward\": 59.0, \"regret\": 12.093800000000002}, {\"step\": 119, \"cum_reward\": 47.3354, \"best_cumreward\": 59.5, \"regret\": 12.1646}, {\"step\": 120, \"cum_reward\": 47.7732, \"best_cumreward\": 60.0, \"regret\": 12.226799999999997}, {\"step\": 121, \"cum_reward\": 48.2078, \"best_cumreward\": 60.5, \"regret\": 12.292200000000001}, {\"step\": 122, \"cum_reward\": 48.6508, \"best_cumreward\": 61.0, \"regret\": 12.349200000000003}, {\"step\": 123, \"cum_reward\": 49.083, \"best_cumreward\": 61.5, \"regret\": 12.417000000000002}, {\"step\": 124, \"cum_reward\": 49.5206, \"best_cumreward\": 62.0, \"regret\": 12.479399999999998}, {\"step\": 125, \"cum_reward\": 49.9526, \"best_cumreward\": 62.5, \"regret\": 12.547400000000003}, {\"step\": 126, \"cum_reward\": 50.3972, \"best_cumreward\": 63.0, \"regret\": 12.602800000000002}, {\"step\": 127, \"cum_reward\": 50.839, \"best_cumreward\": 63.5, \"regret\": 12.661000000000001}, {\"step\": 128, \"cum_reward\": 51.2836, \"best_cumreward\": 64.0, \"regret\": 12.7164}, {\"step\": 129, \"cum_reward\": 51.7184, \"best_cumreward\": 64.5, \"regret\": 12.781599999999997}, {\"step\": 130, \"cum_reward\": 52.1558, \"best_cumreward\": 65.0, \"regret\": 12.8442}, {\"step\": 131, \"cum_reward\": 52.6076, \"best_cumreward\": 65.5, \"regret\": 12.892400000000002}, {\"step\": 132, \"cum_reward\": 53.036, \"best_cumreward\": 66.0, \"regret\": 12.963999999999999}, {\"step\": 133, \"cum_reward\": 53.4714, \"best_cumreward\": 66.5, \"regret\": 13.028599999999997}, {\"step\": 134, \"cum_reward\": 53.915, \"best_cumreward\": 67.0, \"regret\": 13.085}, {\"step\": 135, \"cum_reward\": 54.3508, \"best_cumreward\": 67.5, \"regret\": 13.1492}, {\"step\": 136, \"cum_reward\": 54.788, \"best_cumreward\": 68.0, \"regret\": 13.212000000000003}, {\"step\": 137, \"cum_reward\": 55.2328, \"best_cumreward\": 68.5, \"regret\": 13.267200000000003}, {\"step\": 138, \"cum_reward\": 55.6582, \"best_cumreward\": 69.0, \"regret\": 13.3418}, {\"step\": 139, \"cum_reward\": 56.1028, \"best_cumreward\": 69.5, \"regret\": 13.397199999999998}, {\"step\": 140, \"cum_reward\": 56.551, \"best_cumreward\": 70.0, \"regret\": 13.448999999999998}, {\"step\": 141, \"cum_reward\": 56.9934, \"best_cumreward\": 70.5, \"regret\": 13.506599999999999}, {\"step\": 142, \"cum_reward\": 57.4314, \"best_cumreward\": 71.0, \"regret\": 13.568600000000004}, {\"step\": 143, \"cum_reward\": 57.8894, \"best_cumreward\": 71.5, \"regret\": 13.610599999999998}, {\"step\": 144, \"cum_reward\": 58.3284, \"best_cumreward\": 72.0, \"regret\": 13.671599999999998}, {\"step\": 145, \"cum_reward\": 58.7636, \"best_cumreward\": 72.5, \"regret\": 13.736400000000003}, {\"step\": 146, \"cum_reward\": 59.2082, \"best_cumreward\": 73.0, \"regret\": 13.791800000000002}, {\"step\": 147, \"cum_reward\": 59.6438, \"best_cumreward\": 73.5, \"regret\": 13.856200000000001}, {\"step\": 148, \"cum_reward\": 60.0886, \"best_cumreward\": 74.0, \"regret\": 13.9114}, {\"step\": 149, \"cum_reward\": 60.52, \"best_cumreward\": 74.5, \"regret\": 13.979999999999997}, {\"step\": 150, \"cum_reward\": 60.9574, \"best_cumreward\": 75.0, \"regret\": 14.0426}, {\"step\": 151, \"cum_reward\": 61.4072, \"best_cumreward\": 75.5, \"regret\": 14.092799999999997}, {\"step\": 152, \"cum_reward\": 61.8412, \"best_cumreward\": 76.0, \"regret\": 14.1588}, {\"step\": 153, \"cum_reward\": 62.2814, \"best_cumreward\": 76.5, \"regret\": 14.218600000000002}, {\"step\": 154, \"cum_reward\": 62.7338, \"best_cumreward\": 77.0, \"regret\": 14.266199999999998}, {\"step\": 155, \"cum_reward\": 63.1808, \"best_cumreward\": 77.5, \"regret\": 14.319200000000002}, {\"step\": 156, \"cum_reward\": 63.6328, \"best_cumreward\": 78.0, \"regret\": 14.367199999999997}, {\"step\": 157, \"cum_reward\": 64.0894, \"best_cumreward\": 78.5, \"regret\": 14.410600000000002}, {\"step\": 158, \"cum_reward\": 64.532, \"best_cumreward\": 79.0, \"regret\": 14.468000000000004}, {\"step\": 159, \"cum_reward\": 64.9844, \"best_cumreward\": 79.5, \"regret\": 14.515600000000006}, {\"step\": 160, \"cum_reward\": 65.4338, \"best_cumreward\": 80.0, \"regret\": 14.566199999999995}, {\"step\": 161, \"cum_reward\": 65.8802, \"best_cumreward\": 80.5, \"regret\": 14.619799999999998}, {\"step\": 162, \"cum_reward\": 66.3196, \"best_cumreward\": 81.0, \"regret\": 14.680400000000006}, {\"step\": 163, \"cum_reward\": 66.7794, \"best_cumreward\": 81.5, \"regret\": 14.720600000000005}, {\"step\": 164, \"cum_reward\": 67.234, \"best_cumreward\": 82.0, \"regret\": 14.766000000000005}, {\"step\": 165, \"cum_reward\": 67.685, \"best_cumreward\": 82.5, \"regret\": 14.814999999999998}, {\"step\": 166, \"cum_reward\": 68.1192, \"best_cumreward\": 83.0, \"regret\": 14.880799999999994}, {\"step\": 167, \"cum_reward\": 68.577, \"best_cumreward\": 83.5, \"regret\": 14.923000000000002}, {\"step\": 168, \"cum_reward\": 69.0244, \"best_cumreward\": 84.0, \"regret\": 14.9756}, {\"step\": 169, \"cum_reward\": 69.4812, \"best_cumreward\": 84.5, \"regret\": 15.018799999999999}, {\"step\": 170, \"cum_reward\": 69.9304, \"best_cumreward\": 85.0, \"regret\": 15.069599999999994}, {\"step\": 171, \"cum_reward\": 70.3806, \"best_cumreward\": 85.5, \"regret\": 15.119399999999999}, {\"step\": 172, \"cum_reward\": 70.8312, \"best_cumreward\": 86.0, \"regret\": 15.168800000000005}, {\"step\": 173, \"cum_reward\": 71.2796, \"best_cumreward\": 86.5, \"regret\": 15.220399999999998}, {\"step\": 174, \"cum_reward\": 71.7338, \"best_cumreward\": 87.0, \"regret\": 15.266199999999998}, {\"step\": 175, \"cum_reward\": 72.1814, \"best_cumreward\": 87.5, \"regret\": 15.318600000000004}, {\"step\": 176, \"cum_reward\": 72.6418, \"best_cumreward\": 88.0, \"regret\": 15.358199999999997}, {\"step\": 177, \"cum_reward\": 73.0822, \"best_cumreward\": 88.5, \"regret\": 15.4178}, {\"step\": 178, \"cum_reward\": 73.5384, \"best_cumreward\": 89.0, \"regret\": 15.461600000000004}, {\"step\": 179, \"cum_reward\": 73.9884, \"best_cumreward\": 89.5, \"regret\": 15.511600000000001}, {\"step\": 180, \"cum_reward\": 74.433, \"best_cumreward\": 90.0, \"regret\": 15.566999999999993}, {\"step\": 181, \"cum_reward\": 74.8858, \"best_cumreward\": 90.5, \"regret\": 15.614199999999997}, {\"step\": 182, \"cum_reward\": 75.3292, \"best_cumreward\": 91.0, \"regret\": 15.6708}, {\"step\": 183, \"cum_reward\": 75.7826, \"best_cumreward\": 91.5, \"regret\": 15.717399999999998}, {\"step\": 184, \"cum_reward\": 76.2452, \"best_cumreward\": 92.0, \"regret\": 15.754800000000003}, {\"step\": 185, \"cum_reward\": 76.6894, \"best_cumreward\": 92.5, \"regret\": 15.810599999999994}, {\"step\": 186, \"cum_reward\": 77.148, \"best_cumreward\": 93.0, \"regret\": 15.852000000000004}, {\"step\": 187, \"cum_reward\": 77.5996, \"best_cumreward\": 93.5, \"regret\": 15.900400000000005}, {\"step\": 188, \"cum_reward\": 78.0538, \"best_cumreward\": 94.0, \"regret\": 15.946200000000005}, {\"step\": 189, \"cum_reward\": 78.5028, \"best_cumreward\": 94.5, \"regret\": 15.997200000000007}, {\"step\": 190, \"cum_reward\": 78.965, \"best_cumreward\": 95.0, \"regret\": 16.034999999999997}, {\"step\": 191, \"cum_reward\": 79.4206, \"best_cumreward\": 95.5, \"regret\": 16.079400000000007}, {\"step\": 192, \"cum_reward\": 79.8716, \"best_cumreward\": 96.0, \"regret\": 16.1284}, {\"step\": 193, \"cum_reward\": 80.3274, \"best_cumreward\": 96.5, \"regret\": 16.172600000000003}, {\"step\": 194, \"cum_reward\": 80.801, \"best_cumreward\": 97.0, \"regret\": 16.198999999999998}, {\"step\": 195, \"cum_reward\": 81.263, \"best_cumreward\": 97.5, \"regret\": 16.236999999999995}, {\"step\": 196, \"cum_reward\": 81.7226, \"best_cumreward\": 98.0, \"regret\": 16.2774}, {\"step\": 197, \"cum_reward\": 82.1788, \"best_cumreward\": 98.5, \"regret\": 16.321200000000005}, {\"step\": 198, \"cum_reward\": 82.645, \"best_cumreward\": 99.0, \"regret\": 16.355000000000004}, {\"step\": 199, \"cum_reward\": 83.0928, \"best_cumreward\": 99.5, \"regret\": 16.407200000000003}, {\"step\": 200, \"cum_reward\": 83.5598, \"best_cumreward\": 100.0, \"regret\": 16.440200000000004}, {\"step\": 201, \"cum_reward\": 84.0084, \"best_cumreward\": 100.5, \"regret\": 16.491600000000005}, {\"step\": 202, \"cum_reward\": 84.4786, \"best_cumreward\": 101.0, \"regret\": 16.5214}, {\"step\": 203, \"cum_reward\": 84.9314, \"best_cumreward\": 101.5, \"regret\": 16.568600000000004}, {\"step\": 204, \"cum_reward\": 85.3856, \"best_cumreward\": 102.0, \"regret\": 16.614400000000003}, {\"step\": 205, \"cum_reward\": 85.8486, \"best_cumreward\": 102.5, \"regret\": 16.651399999999995}, {\"step\": 206, \"cum_reward\": 86.3036, \"best_cumreward\": 103.0, \"regret\": 16.696399999999997}, {\"step\": 207, \"cum_reward\": 86.7712, \"best_cumreward\": 103.5, \"regret\": 16.728800000000007}, {\"step\": 208, \"cum_reward\": 87.2326, \"best_cumreward\": 104.0, \"regret\": 16.767399999999995}, {\"step\": 209, \"cum_reward\": 87.702, \"best_cumreward\": 104.5, \"regret\": 16.798000000000002}, {\"step\": 210, \"cum_reward\": 88.1626, \"best_cumreward\": 105.0, \"regret\": 16.837400000000002}, {\"step\": 211, \"cum_reward\": 88.6336, \"best_cumreward\": 105.5, \"regret\": 16.8664}, {\"step\": 212, \"cum_reward\": 89.0786, \"best_cumreward\": 106.0, \"regret\": 16.921400000000006}, {\"step\": 213, \"cum_reward\": 89.546, \"best_cumreward\": 106.5, \"regret\": 16.953999999999994}, {\"step\": 214, \"cum_reward\": 89.9956, \"best_cumreward\": 107.0, \"regret\": 17.004400000000004}, {\"step\": 215, \"cum_reward\": 90.4556, \"best_cumreward\": 107.5, \"regret\": 17.044399999999996}, {\"step\": 216, \"cum_reward\": 90.9156, \"best_cumreward\": 108.0, \"regret\": 17.084400000000002}, {\"step\": 217, \"cum_reward\": 91.3708, \"best_cumreward\": 108.5, \"regret\": 17.129199999999997}, {\"step\": 218, \"cum_reward\": 91.8236, \"best_cumreward\": 109.0, \"regret\": 17.1764}, {\"step\": 219, \"cum_reward\": 92.278, \"best_cumreward\": 109.5, \"regret\": 17.221999999999994}, {\"step\": 220, \"cum_reward\": 92.7462, \"best_cumreward\": 110.0, \"regret\": 17.2538}, {\"step\": 221, \"cum_reward\": 93.2072, \"best_cumreward\": 110.5, \"regret\": 17.2928}, {\"step\": 222, \"cum_reward\": 93.6662, \"best_cumreward\": 111.0, \"regret\": 17.333799999999997}, {\"step\": 223, \"cum_reward\": 94.1284, \"best_cumreward\": 111.5, \"regret\": 17.3716}, {\"step\": 224, \"cum_reward\": 94.5842, \"best_cumreward\": 112.0, \"regret\": 17.415800000000004}, {\"step\": 225, \"cum_reward\": 95.0514, \"best_cumreward\": 112.5, \"regret\": 17.4486}, {\"step\": 226, \"cum_reward\": 95.5148, \"best_cumreward\": 113.0, \"regret\": 17.485200000000006}, {\"step\": 227, \"cum_reward\": 95.9682, \"best_cumreward\": 113.5, \"regret\": 17.531800000000004}, {\"step\": 228, \"cum_reward\": 96.4282, \"best_cumreward\": 114.0, \"regret\": 17.571799999999996}, {\"step\": 229, \"cum_reward\": 96.8772, \"best_cumreward\": 114.5, \"regret\": 17.622799999999998}, {\"step\": 230, \"cum_reward\": 97.3334, \"best_cumreward\": 115.0, \"regret\": 17.666600000000003}, {\"step\": 231, \"cum_reward\": 97.796, \"best_cumreward\": 115.5, \"regret\": 17.703999999999994}, {\"step\": 232, \"cum_reward\": 98.2584, \"best_cumreward\": 116.0, \"regret\": 17.741600000000005}, {\"step\": 233, \"cum_reward\": 98.7298, \"best_cumreward\": 116.5, \"regret\": 17.770200000000003}, {\"step\": 234, \"cum_reward\": 99.1896, \"best_cumreward\": 117.0, \"regret\": 17.8104}, {\"step\": 235, \"cum_reward\": 99.6548, \"best_cumreward\": 117.5, \"regret\": 17.845200000000006}, {\"step\": 236, \"cum_reward\": 100.1216, \"best_cumreward\": 118.0, \"regret\": 17.8784}, {\"step\": 237, \"cum_reward\": 100.5854, \"best_cumreward\": 118.5, \"regret\": 17.914599999999993}, {\"step\": 238, \"cum_reward\": 101.0596, \"best_cumreward\": 119.0, \"regret\": 17.940399999999997}, {\"step\": 239, \"cum_reward\": 101.5364, \"best_cumreward\": 119.5, \"regret\": 17.9636}, {\"step\": 240, \"cum_reward\": 102.0088, \"best_cumreward\": 120.0, \"regret\": 17.991200000000006}, {\"step\": 241, \"cum_reward\": 102.4734, \"best_cumreward\": 120.5, \"regret\": 18.026600000000002}, {\"step\": 242, \"cum_reward\": 102.929, \"best_cumreward\": 121.0, \"regret\": 18.070999999999998}, {\"step\": 243, \"cum_reward\": 103.3936, \"best_cumreward\": 121.5, \"regret\": 18.106399999999994}, {\"step\": 244, \"cum_reward\": 103.8614, \"best_cumreward\": 122.0, \"regret\": 18.138599999999997}, {\"step\": 245, \"cum_reward\": 104.3344, \"best_cumreward\": 122.5, \"regret\": 18.165599999999998}, {\"step\": 246, \"cum_reward\": 104.7912, \"best_cumreward\": 123.0, \"regret\": 18.208799999999997}, {\"step\": 247, \"cum_reward\": 105.2466, \"best_cumreward\": 123.5, \"regret\": 18.2534}, {\"step\": 248, \"cum_reward\": 105.705, \"best_cumreward\": 124.0, \"regret\": 18.295}, {\"step\": 249, \"cum_reward\": 106.1638, \"best_cumreward\": 124.5, \"regret\": 18.336200000000005}, {\"step\": 250, \"cum_reward\": 106.6264, \"best_cumreward\": 125.0, \"regret\": 18.373599999999996}]}}, {\"mode\": \"vega-lite\"});\n",
              "</script>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkoJlveQ1uCb"
      },
      "source": [
        "We observe that Thompson Sampling is the best performer with a cumulative regret of 19."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0VgpyCM2UIv"
      },
      "source": [
        "#Summary\n",
        "In this analysis of Thompson Sampling algorithm, started with the Baye's Rule and used a parametric assumption of Beta distributions for the priors. The overall posterior for each arm's reward function was a combination of Binomial likelihood and Beta prior, which could be represented as another Beta distribution.\n",
        "\n",
        "Compared to the other algorithms, the Thompson Sampling algorithm provides robustness in performance regardless of arms with close reward averages and arms with big difference in reward averages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuqZhxMh0dQ1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}