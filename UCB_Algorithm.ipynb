{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UCB_Algorithm.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgnr_J7R12uR"
      },
      "source": [
        "#UCB Algorithm\n",
        "\n",
        "In UCB algorithm, we are only concerned with the upper bound, given that we are trying to find the arm with the highest reward rate.\n",
        "\n",
        "At each given round of n trials, the reward UCB of all arms are represented by the following:\n",
        "\n",
        "\n",
        "---![ucb_eqn.png](data:image/png;base64,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)\n",
        "\n",
        "\n",
        "where mu_i represents the current reward return average of arm i at the current round, n represents the number of trials passed, and n_i represents the number of pulls given to arm i in the playthrough history.\n",
        "\n",
        "The above formulation is simple but yet has several interesting implications as explained in the following:\n",
        "\n",
        "The upper boundary is proportional to the squared root of ln(n), which means that when the experiment progresses, all arms have their upper boundaries increases by a factor of squared root of ln(n).\n",
        "This upper boundary is inversely proportional to the squared root of n_i. The more times the specific arm has been engaged before in the past, the greater the confidence boundary reduces towards the point estimate. Thereafter, the UCB algorithm always picks the arm with the highest reward UCB as represented by the equation above.\n",
        "\n",
        "A simple thought experiment to glean some intuition on how UCB algorithm incorporates exploration and exploitation.\n",
        "\n",
        "The time complexity between the numerator and denominator provides a tension between exploration and exploitation. For any increase in n, the UCB increases only by logarithmic time, while for any increase in n_i, the UCB decreases by n_i. Thus, an arm that has not been explored as often as other arms will have a bigger UCB component. Depending on its current average mean, the overall UCB function representation of that specific arm may be greater than other arms with higher return but smaller components, and consequently enable that arm to be picked.\n",
        "\n",
        "\n",
        "Below is the code for creation of the UCB algorithm setup and progressive updates of counts and values for arms.\n",
        "\n",
        "Counts: Represent recorded times when arm was pulled.\n",
        "Values: Represent the known mean reward. In the case of a Bernoulli arm, values represent the probability of reward which ranges from 0 to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyPUuW9BvBj1"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import altair as alt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p99k6jYtt4n_"
      },
      "source": [
        "class BernoulliArm():\n",
        "    def __init__(self, p):\n",
        "        self.p = p\n",
        "    \n",
        "    # Reward system based on Bernoulli\n",
        "    def draw(self):\n",
        "        if random.random() > self.p:\n",
        "            return 0.0\n",
        "        else:\n",
        "            return 1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqHW5tEguMhO"
      },
      "source": [
        "def simulation_algorithm(algo, arms, num_sims, horizon):\n",
        "    \n",
        "    # Initialise variables for duration of accumulated simulation (num_sims * horizon_per_simulation)\n",
        "    chosen_arms = [0.0 for i in range(num_sims * horizon)]\n",
        "    rewards = [0.0 for i in range(num_sims * horizon)]\n",
        "    cumulative_rewards = [0 for i in range(num_sims * horizon)]\n",
        "    sim_nums = [0.0 for i in range(num_sims *horizon)]\n",
        "    times = [0.0 for i in range (num_sims*horizon)]\n",
        "    \n",
        "    for sim in range(num_sims):\n",
        "        sim = sim + 1\n",
        "        algo.initialize(len(arms))\n",
        "        \n",
        "        for t in range(horizon):\n",
        "            t = t + 1\n",
        "            index = (sim -1) * horizon + t -1\n",
        "            sim_nums[index] = sim\n",
        "            times[index] = t\n",
        "            \n",
        "            # Selection of best arm and engaging it\n",
        "            chosen_arm = algo.select_arm()\n",
        "            chosen_arms[index] = chosen_arm\n",
        "            \n",
        "            # Engage chosen Bernoulli Arm and obtain reward info\n",
        "            reward = arms[chosen_arm].draw()\n",
        "            rewards[index] = reward\n",
        "            \n",
        "            if t ==1:\n",
        "                cumulative_rewards[index] = reward\n",
        "            else:\n",
        "                cumulative_rewards[index] = cumulative_rewards[index-1] + reward\n",
        "                \n",
        "            algo.update(chosen_arm, reward)\n",
        "    \n",
        "    return [sim_nums, times, chosen_arms, rewards, cumulative_rewards]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04cbDGj6tcgg"
      },
      "source": [
        "class UCB():\n",
        "    def __init__(self, counts, values):\n",
        "        self.counts = counts\n",
        "        self.values = values\n",
        "        return\n",
        "\n",
        "    def initialize(self, n_arms):\n",
        "        self.counts = [0 for col in range(n_arms)]\n",
        "        self.values = [0.0 for col in range(n_arms)]\n",
        "        return\n",
        "    \n",
        "    def select_arm(self):\n",
        "        n_arms = len(self.counts)\n",
        "        for arm in range(n_arms):\n",
        "            if self.counts[arm] == 0:\n",
        "                return arm\n",
        "    \n",
        "        ucb_values = [0.0 for arm in range(n_arms)]\n",
        "        total_counts = sum(self.counts)\n",
        "        \n",
        "        for arm in range(n_arms):\n",
        "            bonus = math.sqrt((2 * math.log(total_counts)) / float(self.counts[arm]))\n",
        "            ucb_values[arm] = self.values[arm] + bonus\n",
        "        return ucb_values.index(max(ucb_values))\n",
        "    \n",
        "    def update(self, chosen_arm, reward):\n",
        "        self.counts[chosen_arm] = self.counts[chosen_arm] + 1\n",
        "        n = self.counts[chosen_arm]\n",
        "        \n",
        "        value = self.values[chosen_arm]\n",
        "        new_value = ((n - 1) / float(n)) * value + (1 / float(n)) * reward\n",
        "        self.values[chosen_arm] = new_value\n",
        "        return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3lVP-RotnI-",
        "outputId": "20e66a27-5578-4522-feeb-49947df3ada8"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import math\n",
        "\n",
        "random.seed(1)\n",
        "# out of 5 arms, 1 arm is clearly the best\n",
        "means = [0.4, 0.3, 0.5, 0.2, 0.1]\n",
        "n_arms = len(means)\n",
        "# Shuffling arms\n",
        "#random.shuffle(means)\n",
        "\n",
        "# Create list of Bernoulli Arms with Reward Information\n",
        "arms = list(map(lambda mu: BernoulliArm(mu), means))\n",
        "print(\"Best arm is \" + str(np.argmax(means)))\n",
        "\n",
        "f = open(\"ucb_results.tsv\", \"w+\")\n",
        "\n",
        "# Create 1 round of 5000 simulations\n",
        "algo = UCB([], [])\n",
        "algo.initialize(n_arms)\n",
        "results = simulation_algorithm(algo, arms, 5000, 250)\n",
        "    \n",
        "# Store data\n",
        "for i in range(len(results[0])):\n",
        "    f.write(\"\\t\".join([str(results[j][i]) for j in range(len(results))]) + \"\\n\")\n",
        "f.close()\n",
        "print(\"Simulation done for UCB algo, now check the result\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best arm is 2\n",
            "Simulation done for UCB algo, now check the result\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "aYK1QOWPtxdB",
        "outputId": "066b6d5c-1e82-44e1-fdef-67c6a4180f2b"
      },
      "source": [
        "\n",
        "df = pd.read_csv(\"/content/ucb_results.tsv\", sep = \"\\t\", header = None, names = [\"simulation_num\", \"step\", \"chosen_arm\", \"reward\", \"cum_reward\"])\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>simulation_num</th>\n",
              "      <th>step</th>\n",
              "      <th>chosen_arm</th>\n",
              "      <th>reward</th>\n",
              "      <th>cum_reward</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   simulation_num  step  chosen_arm  reward  cum_reward\n",
              "0               1     1           0     1.0         1.0\n",
              "1               1     2           1     0.0         1.0\n",
              "2               1     3           2     0.0         1.0\n",
              "3               1     4           3     0.0         1.0\n",
              "4               1     5           4     0.0         1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiufSk2Lufn_"
      },
      "source": [
        "# Create a flag for each step to see if best arm was chosen\n",
        "df[\"chose_correct\"] = np.select(\n",
        "    [\n",
        "        df[\"chosen_arm\"] == 2,\n",
        "        df[\"chosen_arm\"] != 2\n",
        "    ],\n",
        "    [\n",
        "        1,\n",
        "        0\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFwv2QSauq0i"
      },
      "source": [
        "# Perform average/mean for each step for all simulations and epsilon\n",
        "df_chose_correctly = df.loc[:,[\"step\", \"chose_correct\"]].groupby([\"step\"]).agg(\"mean\")\n",
        "\n",
        "# Remove multi index grouping\n",
        "df_chose_correctly = df_chose_correctly.reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJktmjBButes"
      },
      "source": [
        "df_chose_count = df.loc[:,[\"step\",\"chose_correct\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "mZ3jOjp6uw3g",
        "outputId": "3989086c-8f5a-4589-fced-cfefa0871364"
      },
      "source": [
        "df_chose_count"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>step</th>\n",
              "      <th>chose_correct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1249995</th>\n",
              "      <td>246</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1249996</th>\n",
              "      <td>247</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1249997</th>\n",
              "      <td>248</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1249998</th>\n",
              "      <td>249</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1249999</th>\n",
              "      <td>250</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1250000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         step  chose_correct\n",
              "0           1              0\n",
              "1           2              0\n",
              "2           3              0\n",
              "3           4              0\n",
              "4           5              1\n",
              "...       ...            ...\n",
              "1249995   246              1\n",
              "1249996   247              1\n",
              "1249997   248              1\n",
              "1249998   249              0\n",
              "1249999   250              1\n",
              "\n",
              "[1250000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "iV-h7QA1uzRt",
        "outputId": "4424d060-4698-4e94-d43a-b097dd2cee10"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist(df[\"chosen_arm\"])\n",
        "plt.title('Histogram of Arm selections')\n",
        "plt.xlabel('Arms')\n",
        "plt.ylabel('Number of times each Arm was selected')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "7JaXXuS-u3uZ",
        "outputId": "0e954884-1eb0-42f5-b951-e8d8c6926cd4"
      },
      "source": [
        "\n",
        "alt.Chart(df_chose_correctly).mark_line().encode(\n",
        "    alt.X(\"step:Q\", title = \"Time Step\"),\n",
        "    alt.Y(\"chose_correct:Q\", title = \"Mean Rate of Choosing Best Arm\", scale = alt.Scale(domain = [0, 1])),\n",
        ").properties(\n",
        "    title = \"UCB: Mean Rate of Choosing Best Arm from 5000 Simulations. 5 Arms = [0.4, 0.3, 0.5, 0.2, 0.1]\",\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "alt.Chart(...)"
            ],
            "text/html": [
              "\n",
              "<div id=\"altair-viz-4bf1fd9e57da4397991886c0dccea304\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "  (function(spec, embedOpt){\n",
              "    let outputDiv = document.currentScript.previousElementSibling;\n",
              "    if (outputDiv.id !== \"altair-viz-4bf1fd9e57da4397991886c0dccea304\") {\n",
              "      outputDiv = document.getElementById(\"altair-viz-4bf1fd9e57da4397991886c0dccea304\");\n",
              "    }\n",
              "    const paths = {\n",
              "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
              "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
              "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
              "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
              "    };\n",
              "\n",
              "    function loadScript(lib) {\n",
              "      return new Promise(function(resolve, reject) {\n",
              "        var s = document.createElement('script');\n",
              "        s.src = paths[lib];\n",
              "        s.async = true;\n",
              "        s.onload = () => resolve(paths[lib]);\n",
              "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
              "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "      });\n",
              "    }\n",
              "\n",
              "    function showError(err) {\n",
              "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
              "      throw err;\n",
              "    }\n",
              "\n",
              "    function displayChart(vegaEmbed) {\n",
              "      vegaEmbed(outputDiv, spec, embedOpt)\n",
              "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
              "    }\n",
              "\n",
              "    if(typeof define === \"function\" && define.amd) {\n",
              "      requirejs.config({paths});\n",
              "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
              "    } else if (typeof vegaEmbed === \"function\") {\n",
              "      displayChart(vegaEmbed);\n",
              "    } else {\n",
              "      loadScript(\"vega\")\n",
              "        .then(() => loadScript(\"vega-lite\"))\n",
              "        .then(() => loadScript(\"vega-embed\"))\n",
              "        .catch(showError)\n",
              "        .then(() => displayChart(vegaEmbed));\n",
              "    }\n",
              "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-ed87bcca323c859cfb2dea1ec8a40e2b\"}, \"mark\": \"line\", \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"step\", \"title\": \"Time Step\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"chose_correct\", \"scale\": {\"domain\": [0, 1]}, \"title\": \"Mean Rate of Choosing Best Arm\"}}, \"title\": \"UCB: Mean Rate of Choosing Best Arm from 5000 Simulations. 5 Arms = [0.4, 0.3, 0.5, 0.2, 0.1]\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-ed87bcca323c859cfb2dea1ec8a40e2b\": [{\"step\": 1, \"chose_correct\": 0.0}, {\"step\": 2, \"chose_correct\": 0.0}, {\"step\": 3, \"chose_correct\": 1.0}, {\"step\": 4, \"chose_correct\": 0.0}, {\"step\": 5, \"chose_correct\": 0.0}, {\"step\": 6, \"chose_correct\": 0.2008}, {\"step\": 7, \"chose_correct\": 0.2946}, {\"step\": 8, \"chose_correct\": 0.4444}, {\"step\": 9, \"chose_correct\": 0.2394}, {\"step\": 10, \"chose_correct\": 0.1234}, {\"step\": 11, \"chose_correct\": 0.1264}, {\"step\": 12, \"chose_correct\": 0.2904}, {\"step\": 13, \"chose_correct\": 0.347}, {\"step\": 14, \"chose_correct\": 0.2932}, {\"step\": 15, \"chose_correct\": 0.3186}, {\"step\": 16, \"chose_correct\": 0.3498}, {\"step\": 17, \"chose_correct\": 0.2896}, {\"step\": 18, \"chose_correct\": 0.2486}, {\"step\": 19, \"chose_correct\": 0.218}, {\"step\": 20, \"chose_correct\": 0.2142}, {\"step\": 21, \"chose_correct\": 0.2736}, {\"step\": 22, \"chose_correct\": 0.3446}, {\"step\": 23, \"chose_correct\": 0.333}, {\"step\": 24, \"chose_correct\": 0.3274}, {\"step\": 25, \"chose_correct\": 0.3302}, {\"step\": 26, \"chose_correct\": 0.324}, {\"step\": 27, \"chose_correct\": 0.3162}, {\"step\": 28, \"chose_correct\": 0.2856}, {\"step\": 29, \"chose_correct\": 0.3064}, {\"step\": 30, \"chose_correct\": 0.3014}, {\"step\": 31, \"chose_correct\": 0.3112}, {\"step\": 32, \"chose_correct\": 0.317}, {\"step\": 33, \"chose_correct\": 0.3252}, {\"step\": 34, \"chose_correct\": 0.3242}, {\"step\": 35, \"chose_correct\": 0.3228}, {\"step\": 36, \"chose_correct\": 0.3214}, {\"step\": 37, \"chose_correct\": 0.318}, {\"step\": 38, \"chose_correct\": 0.3184}, {\"step\": 39, \"chose_correct\": 0.329}, {\"step\": 40, \"chose_correct\": 0.3126}, {\"step\": 41, \"chose_correct\": 0.325}, {\"step\": 42, \"chose_correct\": 0.3112}, {\"step\": 43, \"chose_correct\": 0.3244}, {\"step\": 44, \"chose_correct\": 0.3276}, {\"step\": 45, \"chose_correct\": 0.3154}, {\"step\": 46, \"chose_correct\": 0.3196}, {\"step\": 47, \"chose_correct\": 0.3356}, {\"step\": 48, \"chose_correct\": 0.3528}, {\"step\": 49, \"chose_correct\": 0.347}, {\"step\": 50, \"chose_correct\": 0.3204}, {\"step\": 51, \"chose_correct\": 0.3272}, {\"step\": 52, \"chose_correct\": 0.3388}, {\"step\": 53, \"chose_correct\": 0.342}, {\"step\": 54, \"chose_correct\": 0.3484}, {\"step\": 55, \"chose_correct\": 0.3394}, {\"step\": 56, \"chose_correct\": 0.3398}, {\"step\": 57, \"chose_correct\": 0.3664}, {\"step\": 58, \"chose_correct\": 0.357}, {\"step\": 59, \"chose_correct\": 0.3406}, {\"step\": 60, \"chose_correct\": 0.3472}, {\"step\": 61, \"chose_correct\": 0.3496}, {\"step\": 62, \"chose_correct\": 0.3562}, {\"step\": 63, \"chose_correct\": 0.355}, {\"step\": 64, \"chose_correct\": 0.364}, {\"step\": 65, \"chose_correct\": 0.3484}, {\"step\": 66, \"chose_correct\": 0.3436}, {\"step\": 67, \"chose_correct\": 0.3584}, {\"step\": 68, \"chose_correct\": 0.365}, {\"step\": 69, \"chose_correct\": 0.3554}, {\"step\": 70, \"chose_correct\": 0.359}, {\"step\": 71, \"chose_correct\": 0.3752}, {\"step\": 72, \"chose_correct\": 0.3662}, {\"step\": 73, \"chose_correct\": 0.3624}, {\"step\": 74, \"chose_correct\": 0.3562}, {\"step\": 75, \"chose_correct\": 0.3602}, {\"step\": 76, \"chose_correct\": 0.3656}, {\"step\": 77, \"chose_correct\": 0.3688}, {\"step\": 78, \"chose_correct\": 0.3698}, {\"step\": 79, \"chose_correct\": 0.3752}, {\"step\": 80, \"chose_correct\": 0.3804}, {\"step\": 81, \"chose_correct\": 0.3778}, {\"step\": 82, \"chose_correct\": 0.3722}, {\"step\": 83, \"chose_correct\": 0.3776}, {\"step\": 84, \"chose_correct\": 0.382}, {\"step\": 85, \"chose_correct\": 0.3838}, {\"step\": 86, \"chose_correct\": 0.377}, {\"step\": 87, \"chose_correct\": 0.3822}, {\"step\": 88, \"chose_correct\": 0.3824}, {\"step\": 89, \"chose_correct\": 0.3652}, {\"step\": 90, \"chose_correct\": 0.3648}, {\"step\": 91, \"chose_correct\": 0.3796}, {\"step\": 92, \"chose_correct\": 0.3702}, {\"step\": 93, \"chose_correct\": 0.3716}, {\"step\": 94, \"chose_correct\": 0.3592}, {\"step\": 95, \"chose_correct\": 0.3736}, {\"step\": 96, \"chose_correct\": 0.3864}, {\"step\": 97, \"chose_correct\": 0.39}, {\"step\": 98, \"chose_correct\": 0.3914}, {\"step\": 99, \"chose_correct\": 0.3948}, {\"step\": 100, \"chose_correct\": 0.3872}, {\"step\": 101, \"chose_correct\": 0.3916}, {\"step\": 102, \"chose_correct\": 0.4044}, {\"step\": 103, \"chose_correct\": 0.3988}, {\"step\": 104, \"chose_correct\": 0.409}, {\"step\": 105, \"chose_correct\": 0.4012}, {\"step\": 106, \"chose_correct\": 0.4008}, {\"step\": 107, \"chose_correct\": 0.3902}, {\"step\": 108, \"chose_correct\": 0.3962}, {\"step\": 109, \"chose_correct\": 0.405}, {\"step\": 110, \"chose_correct\": 0.3976}, {\"step\": 111, \"chose_correct\": 0.4014}, {\"step\": 112, \"chose_correct\": 0.4154}, {\"step\": 113, \"chose_correct\": 0.3952}, {\"step\": 114, \"chose_correct\": 0.4098}, {\"step\": 115, \"chose_correct\": 0.3936}, {\"step\": 116, \"chose_correct\": 0.4002}, {\"step\": 117, \"chose_correct\": 0.4002}, {\"step\": 118, \"chose_correct\": 0.4034}, {\"step\": 119, \"chose_correct\": 0.416}, {\"step\": 120, \"chose_correct\": 0.4184}, {\"step\": 121, \"chose_correct\": 0.402}, {\"step\": 122, \"chose_correct\": 0.404}, {\"step\": 123, \"chose_correct\": 0.4098}, {\"step\": 124, \"chose_correct\": 0.4134}, {\"step\": 125, \"chose_correct\": 0.403}, {\"step\": 126, \"chose_correct\": 0.4074}, {\"step\": 127, \"chose_correct\": 0.4186}, {\"step\": 128, \"chose_correct\": 0.4214}, {\"step\": 129, \"chose_correct\": 0.4292}, {\"step\": 130, \"chose_correct\": 0.419}, {\"step\": 131, \"chose_correct\": 0.421}, {\"step\": 132, \"chose_correct\": 0.4156}, {\"step\": 133, \"chose_correct\": 0.4116}, {\"step\": 134, \"chose_correct\": 0.4168}, {\"step\": 135, \"chose_correct\": 0.4206}, {\"step\": 136, \"chose_correct\": 0.4306}, {\"step\": 137, \"chose_correct\": 0.4306}, {\"step\": 138, \"chose_correct\": 0.4178}, {\"step\": 139, \"chose_correct\": 0.4192}, {\"step\": 140, \"chose_correct\": 0.4254}, {\"step\": 141, \"chose_correct\": 0.4272}, {\"step\": 142, \"chose_correct\": 0.431}, {\"step\": 143, \"chose_correct\": 0.4228}, {\"step\": 144, \"chose_correct\": 0.4386}, {\"step\": 145, \"chose_correct\": 0.4354}, {\"step\": 146, \"chose_correct\": 0.435}, {\"step\": 147, \"chose_correct\": 0.4252}, {\"step\": 148, \"chose_correct\": 0.4348}, {\"step\": 149, \"chose_correct\": 0.4236}, {\"step\": 150, \"chose_correct\": 0.4374}, {\"step\": 151, \"chose_correct\": 0.4314}, {\"step\": 152, \"chose_correct\": 0.4354}, {\"step\": 153, \"chose_correct\": 0.4446}, {\"step\": 154, \"chose_correct\": 0.4314}, {\"step\": 155, \"chose_correct\": 0.4368}, {\"step\": 156, \"chose_correct\": 0.4386}, {\"step\": 157, \"chose_correct\": 0.4288}, {\"step\": 158, \"chose_correct\": 0.4424}, {\"step\": 159, \"chose_correct\": 0.441}, {\"step\": 160, \"chose_correct\": 0.4368}, {\"step\": 161, \"chose_correct\": 0.4402}, {\"step\": 162, \"chose_correct\": 0.4322}, {\"step\": 163, \"chose_correct\": 0.4358}, {\"step\": 164, \"chose_correct\": 0.4494}, {\"step\": 165, \"chose_correct\": 0.4398}, {\"step\": 166, \"chose_correct\": 0.4436}, {\"step\": 167, \"chose_correct\": 0.4422}, {\"step\": 168, \"chose_correct\": 0.4372}, {\"step\": 169, \"chose_correct\": 0.4366}, {\"step\": 170, \"chose_correct\": 0.4478}, {\"step\": 171, \"chose_correct\": 0.4454}, {\"step\": 172, \"chose_correct\": 0.4526}, {\"step\": 173, \"chose_correct\": 0.448}, {\"step\": 174, \"chose_correct\": 0.457}, {\"step\": 175, \"chose_correct\": 0.4656}, {\"step\": 176, \"chose_correct\": 0.4544}, {\"step\": 177, \"chose_correct\": 0.4634}, {\"step\": 178, \"chose_correct\": 0.4524}, {\"step\": 179, \"chose_correct\": 0.4518}, {\"step\": 180, \"chose_correct\": 0.4508}, {\"step\": 181, \"chose_correct\": 0.4634}, {\"step\": 182, \"chose_correct\": 0.4596}, {\"step\": 183, \"chose_correct\": 0.4498}, {\"step\": 184, \"chose_correct\": 0.46}, {\"step\": 185, \"chose_correct\": 0.4666}, {\"step\": 186, \"chose_correct\": 0.4568}, {\"step\": 187, \"chose_correct\": 0.4606}, {\"step\": 188, \"chose_correct\": 0.458}, {\"step\": 189, \"chose_correct\": 0.4442}, {\"step\": 190, \"chose_correct\": 0.4614}, {\"step\": 191, \"chose_correct\": 0.4764}, {\"step\": 192, \"chose_correct\": 0.4744}, {\"step\": 193, \"chose_correct\": 0.4576}, {\"step\": 194, \"chose_correct\": 0.4648}, {\"step\": 195, \"chose_correct\": 0.473}, {\"step\": 196, \"chose_correct\": 0.47}, {\"step\": 197, \"chose_correct\": 0.478}, {\"step\": 198, \"chose_correct\": 0.47}, {\"step\": 199, \"chose_correct\": 0.4768}, {\"step\": 200, \"chose_correct\": 0.469}, {\"step\": 201, \"chose_correct\": 0.4626}, {\"step\": 202, \"chose_correct\": 0.4678}, {\"step\": 203, \"chose_correct\": 0.4688}, {\"step\": 204, \"chose_correct\": 0.4628}, {\"step\": 205, \"chose_correct\": 0.4642}, {\"step\": 206, \"chose_correct\": 0.4766}, {\"step\": 207, \"chose_correct\": 0.4752}, {\"step\": 208, \"chose_correct\": 0.4722}, {\"step\": 209, \"chose_correct\": 0.4684}, {\"step\": 210, \"chose_correct\": 0.4806}, {\"step\": 211, \"chose_correct\": 0.4732}, {\"step\": 212, \"chose_correct\": 0.4662}, {\"step\": 213, \"chose_correct\": 0.4672}, {\"step\": 214, \"chose_correct\": 0.4734}, {\"step\": 215, \"chose_correct\": 0.465}, {\"step\": 216, \"chose_correct\": 0.4738}, {\"step\": 217, \"chose_correct\": 0.4824}, {\"step\": 218, \"chose_correct\": 0.4808}, {\"step\": 219, \"chose_correct\": 0.4782}, {\"step\": 220, \"chose_correct\": 0.4676}, {\"step\": 221, \"chose_correct\": 0.4686}, {\"step\": 222, \"chose_correct\": 0.4742}, {\"step\": 223, \"chose_correct\": 0.4772}, {\"step\": 224, \"chose_correct\": 0.4664}, {\"step\": 225, \"chose_correct\": 0.4788}, {\"step\": 226, \"chose_correct\": 0.4696}, {\"step\": 227, \"chose_correct\": 0.479}, {\"step\": 228, \"chose_correct\": 0.4792}, {\"step\": 229, \"chose_correct\": 0.4704}, {\"step\": 230, \"chose_correct\": 0.473}, {\"step\": 231, \"chose_correct\": 0.476}, {\"step\": 232, \"chose_correct\": 0.4778}, {\"step\": 233, \"chose_correct\": 0.4706}, {\"step\": 234, \"chose_correct\": 0.4802}, {\"step\": 235, \"chose_correct\": 0.4876}, {\"step\": 236, \"chose_correct\": 0.4782}, {\"step\": 237, \"chose_correct\": 0.4766}, {\"step\": 238, \"chose_correct\": 0.472}, {\"step\": 239, \"chose_correct\": 0.482}, {\"step\": 240, \"chose_correct\": 0.4888}, {\"step\": 241, \"chose_correct\": 0.489}, {\"step\": 242, \"chose_correct\": 0.4936}, {\"step\": 243, \"chose_correct\": 0.4936}, {\"step\": 244, \"chose_correct\": 0.4868}, {\"step\": 245, \"chose_correct\": 0.496}, {\"step\": 246, \"chose_correct\": 0.4976}, {\"step\": 247, \"chose_correct\": 0.4908}, {\"step\": 248, \"chose_correct\": 0.5044}, {\"step\": 249, \"chose_correct\": 0.4976}, {\"step\": 250, \"chose_correct\": 0.4966}]}}, {\"mode\": \"vega-lite\"});\n",
              "</script>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5m_X4xDE4FRn"
      },
      "source": [
        "The UCB algorithm has extreme fluctuations in its rate of choosing the best arm in the early phases of the experiment as shown by time steps between 0 to 20. This can be explained by the emphasis of exploration amongst all arms since the UCB components for all arms are much bigger at the start.\n",
        "\n",
        "As the trial progresses, the UCB components becomes much smaller for all arms, and the UCB function representation of each arm converges towards the average reward mean of each arm. Thus, the arm with the higher mean becomes more distinguishable by the algorithm and becomes more frequently picked as the trial progresses. Thus, we observe that the rate of choosing the best arm does not seem to have a hard asymptote, but converges towards 0.5. The rate of convergence towards 0.5 slows down as it approaches 0.5, and the experiment time horizon was too short for us to observe any further convergence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzIafUODu8VC"
      },
      "source": [
        "df_cumreward = df.loc[:,[\"step\", \"cum_reward\"]].groupby([\"step\"]).agg(\"mean\").reset_index()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "iWkj0yFLvJoZ",
        "outputId": "f81d3cc8-9d5b-4f1b-872c-0044771226cd"
      },
      "source": [
        "alt.Chart(df_cumreward).mark_line().encode(\n",
        "    alt.X(\"step:Q\", title = \"Time Step\"),\n",
        "    alt.Y(\"cum_reward:Q\", title = \"Mean Cumulative Reward\")\n",
        ").properties(\n",
        "    title = \"UCB: Mean Cumulative Reward from 5000 Simulations. 5 Arms = [0.4,0.3,0.5,0.2, 0.1]\",\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "alt.Chart(...)"
            ],
            "text/html": [
              "\n",
              "<div id=\"altair-viz-c2179569f9d64b5289a47433929e3f7d\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "  (function(spec, embedOpt){\n",
              "    let outputDiv = document.currentScript.previousElementSibling;\n",
              "    if (outputDiv.id !== \"altair-viz-c2179569f9d64b5289a47433929e3f7d\") {\n",
              "      outputDiv = document.getElementById(\"altair-viz-c2179569f9d64b5289a47433929e3f7d\");\n",
              "    }\n",
              "    const paths = {\n",
              "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
              "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
              "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
              "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
              "    };\n",
              "\n",
              "    function loadScript(lib) {\n",
              "      return new Promise(function(resolve, reject) {\n",
              "        var s = document.createElement('script');\n",
              "        s.src = paths[lib];\n",
              "        s.async = true;\n",
              "        s.onload = () => resolve(paths[lib]);\n",
              "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
              "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "      });\n",
              "    }\n",
              "\n",
              "    function showError(err) {\n",
              "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
              "      throw err;\n",
              "    }\n",
              "\n",
              "    function displayChart(vegaEmbed) {\n",
              "      vegaEmbed(outputDiv, spec, embedOpt)\n",
              "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
              "    }\n",
              "\n",
              "    if(typeof define === \"function\" && define.amd) {\n",
              "      requirejs.config({paths});\n",
              "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
              "    } else if (typeof vegaEmbed === \"function\") {\n",
              "      displayChart(vegaEmbed);\n",
              "    } else {\n",
              "      loadScript(\"vega\")\n",
              "        .then(() => loadScript(\"vega-lite\"))\n",
              "        .then(() => loadScript(\"vega-embed\"))\n",
              "        .catch(showError)\n",
              "        .then(() => displayChart(vegaEmbed));\n",
              "    }\n",
              "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-c1b457c791c8ea6c87a2229e53c248ed\"}, \"mark\": \"line\", \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"step\", \"title\": \"Time Step\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"cum_reward\", \"title\": \"Mean Cumulative Reward\"}}, \"title\": \"UCB: Mean Cumulative Reward from 5000 Simulations. 5 Arms = [0.4,0.3,0.5,0.2, 0.1]\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-c1b457c791c8ea6c87a2229e53c248ed\": [{\"step\": 1, \"cum_reward\": 0.406}, {\"step\": 2, \"cum_reward\": 0.7076}, {\"step\": 3, \"cum_reward\": 1.1972}, {\"step\": 4, \"cum_reward\": 1.4126}, {\"step\": 5, \"cum_reward\": 1.5068}, {\"step\": 6, \"cum_reward\": 1.8904}, {\"step\": 7, \"cum_reward\": 2.262}, {\"step\": 8, \"cum_reward\": 2.6564}, {\"step\": 9, \"cum_reward\": 2.9702}, {\"step\": 10, \"cum_reward\": 3.1784}, {\"step\": 11, \"cum_reward\": 3.4918}, {\"step\": 12, \"cum_reward\": 3.8224}, {\"step\": 13, \"cum_reward\": 4.182}, {\"step\": 14, \"cum_reward\": 4.5276}, {\"step\": 15, \"cum_reward\": 4.8988}, {\"step\": 16, \"cum_reward\": 5.2598}, {\"step\": 17, \"cum_reward\": 5.6106}, {\"step\": 18, \"cum_reward\": 5.9336}, {\"step\": 19, \"cum_reward\": 6.238}, {\"step\": 20, \"cum_reward\": 6.5322}, {\"step\": 21, \"cum_reward\": 6.8558}, {\"step\": 22, \"cum_reward\": 7.2108}, {\"step\": 23, \"cum_reward\": 7.5684}, {\"step\": 24, \"cum_reward\": 7.9332}, {\"step\": 25, \"cum_reward\": 8.3028}, {\"step\": 26, \"cum_reward\": 8.6636}, {\"step\": 27, \"cum_reward\": 9.0144}, {\"step\": 28, \"cum_reward\": 9.357}, {\"step\": 29, \"cum_reward\": 9.6982}, {\"step\": 30, \"cum_reward\": 10.041}, {\"step\": 31, \"cum_reward\": 10.3716}, {\"step\": 32, \"cum_reward\": 10.7074}, {\"step\": 33, \"cum_reward\": 11.0564}, {\"step\": 34, \"cum_reward\": 11.4076}, {\"step\": 35, \"cum_reward\": 11.7526}, {\"step\": 36, \"cum_reward\": 12.1036}, {\"step\": 37, \"cum_reward\": 12.4562}, {\"step\": 38, \"cum_reward\": 12.8026}, {\"step\": 39, \"cum_reward\": 13.1552}, {\"step\": 40, \"cum_reward\": 13.501}, {\"step\": 41, \"cum_reward\": 13.8616}, {\"step\": 42, \"cum_reward\": 14.2126}, {\"step\": 43, \"cum_reward\": 14.5654}, {\"step\": 44, \"cum_reward\": 14.9154}, {\"step\": 45, \"cum_reward\": 15.2682}, {\"step\": 46, \"cum_reward\": 15.6126}, {\"step\": 47, \"cum_reward\": 15.9664}, {\"step\": 48, \"cum_reward\": 16.328}, {\"step\": 49, \"cum_reward\": 16.6888}, {\"step\": 50, \"cum_reward\": 17.0348}, {\"step\": 51, \"cum_reward\": 17.3784}, {\"step\": 52, \"cum_reward\": 17.733}, {\"step\": 53, \"cum_reward\": 18.0918}, {\"step\": 54, \"cum_reward\": 18.4388}, {\"step\": 55, \"cum_reward\": 18.7938}, {\"step\": 56, \"cum_reward\": 19.1542}, {\"step\": 57, \"cum_reward\": 19.5148}, {\"step\": 58, \"cum_reward\": 19.875}, {\"step\": 59, \"cum_reward\": 20.245}, {\"step\": 60, \"cum_reward\": 20.607}, {\"step\": 61, \"cum_reward\": 20.9708}, {\"step\": 62, \"cum_reward\": 21.328}, {\"step\": 63, \"cum_reward\": 21.6908}, {\"step\": 64, \"cum_reward\": 22.0556}, {\"step\": 65, \"cum_reward\": 22.4138}, {\"step\": 66, \"cum_reward\": 22.7722}, {\"step\": 67, \"cum_reward\": 23.1452}, {\"step\": 68, \"cum_reward\": 23.5096}, {\"step\": 69, \"cum_reward\": 23.8714}, {\"step\": 70, \"cum_reward\": 24.2264}, {\"step\": 71, \"cum_reward\": 24.5944}, {\"step\": 72, \"cum_reward\": 24.9674}, {\"step\": 73, \"cum_reward\": 25.3232}, {\"step\": 74, \"cum_reward\": 25.684}, {\"step\": 75, \"cum_reward\": 26.0422}, {\"step\": 76, \"cum_reward\": 26.413}, {\"step\": 77, \"cum_reward\": 26.7822}, {\"step\": 78, \"cum_reward\": 27.1548}, {\"step\": 79, \"cum_reward\": 27.5246}, {\"step\": 80, \"cum_reward\": 27.8964}, {\"step\": 81, \"cum_reward\": 28.2758}, {\"step\": 82, \"cum_reward\": 28.6312}, {\"step\": 83, \"cum_reward\": 28.9944}, {\"step\": 84, \"cum_reward\": 29.3646}, {\"step\": 85, \"cum_reward\": 29.7454}, {\"step\": 86, \"cum_reward\": 30.121}, {\"step\": 87, \"cum_reward\": 30.4958}, {\"step\": 88, \"cum_reward\": 30.8624}, {\"step\": 89, \"cum_reward\": 31.235}, {\"step\": 90, \"cum_reward\": 31.5994}, {\"step\": 91, \"cum_reward\": 31.973}, {\"step\": 92, \"cum_reward\": 32.344}, {\"step\": 93, \"cum_reward\": 32.7092}, {\"step\": 94, \"cum_reward\": 33.0758}, {\"step\": 95, \"cum_reward\": 33.4446}, {\"step\": 96, \"cum_reward\": 33.8164}, {\"step\": 97, \"cum_reward\": 34.1882}, {\"step\": 98, \"cum_reward\": 34.5602}, {\"step\": 99, \"cum_reward\": 34.9238}, {\"step\": 100, \"cum_reward\": 35.2984}, {\"step\": 101, \"cum_reward\": 35.6768}, {\"step\": 102, \"cum_reward\": 36.0448}, {\"step\": 103, \"cum_reward\": 36.4202}, {\"step\": 104, \"cum_reward\": 36.7926}, {\"step\": 105, \"cum_reward\": 37.1692}, {\"step\": 106, \"cum_reward\": 37.5448}, {\"step\": 107, \"cum_reward\": 37.9216}, {\"step\": 108, \"cum_reward\": 38.3048}, {\"step\": 109, \"cum_reward\": 38.6882}, {\"step\": 110, \"cum_reward\": 39.0692}, {\"step\": 111, \"cum_reward\": 39.4492}, {\"step\": 112, \"cum_reward\": 39.8386}, {\"step\": 113, \"cum_reward\": 40.2122}, {\"step\": 114, \"cum_reward\": 40.5864}, {\"step\": 115, \"cum_reward\": 40.9742}, {\"step\": 116, \"cum_reward\": 41.3432}, {\"step\": 117, \"cum_reward\": 41.7224}, {\"step\": 118, \"cum_reward\": 42.096}, {\"step\": 119, \"cum_reward\": 42.4726}, {\"step\": 120, \"cum_reward\": 42.8546}, {\"step\": 121, \"cum_reward\": 43.2248}, {\"step\": 122, \"cum_reward\": 43.6022}, {\"step\": 123, \"cum_reward\": 43.9832}, {\"step\": 124, \"cum_reward\": 44.3632}, {\"step\": 125, \"cum_reward\": 44.736}, {\"step\": 126, \"cum_reward\": 45.1172}, {\"step\": 127, \"cum_reward\": 45.497}, {\"step\": 128, \"cum_reward\": 45.8834}, {\"step\": 129, \"cum_reward\": 46.2682}, {\"step\": 130, \"cum_reward\": 46.6466}, {\"step\": 131, \"cum_reward\": 47.0382}, {\"step\": 132, \"cum_reward\": 47.4146}, {\"step\": 133, \"cum_reward\": 47.7914}, {\"step\": 134, \"cum_reward\": 48.175}, {\"step\": 135, \"cum_reward\": 48.5538}, {\"step\": 136, \"cum_reward\": 48.9436}, {\"step\": 137, \"cum_reward\": 49.3318}, {\"step\": 138, \"cum_reward\": 49.7028}, {\"step\": 139, \"cum_reward\": 50.0888}, {\"step\": 140, \"cum_reward\": 50.4858}, {\"step\": 141, \"cum_reward\": 50.8764}, {\"step\": 142, \"cum_reward\": 51.258}, {\"step\": 143, \"cum_reward\": 51.6496}, {\"step\": 144, \"cum_reward\": 52.0296}, {\"step\": 145, \"cum_reward\": 52.4124}, {\"step\": 146, \"cum_reward\": 52.8024}, {\"step\": 147, \"cum_reward\": 53.1842}, {\"step\": 148, \"cum_reward\": 53.5686}, {\"step\": 149, \"cum_reward\": 53.942}, {\"step\": 150, \"cum_reward\": 54.316}, {\"step\": 151, \"cum_reward\": 54.706}, {\"step\": 152, \"cum_reward\": 55.089}, {\"step\": 153, \"cum_reward\": 55.4762}, {\"step\": 154, \"cum_reward\": 55.8674}, {\"step\": 155, \"cum_reward\": 56.2542}, {\"step\": 156, \"cum_reward\": 56.651}, {\"step\": 157, \"cum_reward\": 57.0414}, {\"step\": 158, \"cum_reward\": 57.4236}, {\"step\": 159, \"cum_reward\": 57.8128}, {\"step\": 160, \"cum_reward\": 58.2}, {\"step\": 161, \"cum_reward\": 58.59}, {\"step\": 162, \"cum_reward\": 58.9724}, {\"step\": 163, \"cum_reward\": 59.3672}, {\"step\": 164, \"cum_reward\": 59.765}, {\"step\": 165, \"cum_reward\": 60.1438}, {\"step\": 166, \"cum_reward\": 60.5246}, {\"step\": 167, \"cum_reward\": 60.917}, {\"step\": 168, \"cum_reward\": 61.302}, {\"step\": 169, \"cum_reward\": 61.6922}, {\"step\": 170, \"cum_reward\": 62.0808}, {\"step\": 171, \"cum_reward\": 62.4678}, {\"step\": 172, \"cum_reward\": 62.8594}, {\"step\": 173, \"cum_reward\": 63.2462}, {\"step\": 174, \"cum_reward\": 63.6412}, {\"step\": 175, \"cum_reward\": 64.0294}, {\"step\": 176, \"cum_reward\": 64.4282}, {\"step\": 177, \"cum_reward\": 64.811}, {\"step\": 178, \"cum_reward\": 65.2026}, {\"step\": 179, \"cum_reward\": 65.5966}, {\"step\": 180, \"cum_reward\": 65.9844}, {\"step\": 181, \"cum_reward\": 66.3786}, {\"step\": 182, \"cum_reward\": 66.7648}, {\"step\": 183, \"cum_reward\": 67.1534}, {\"step\": 184, \"cum_reward\": 67.5518}, {\"step\": 185, \"cum_reward\": 67.9374}, {\"step\": 186, \"cum_reward\": 68.3344}, {\"step\": 187, \"cum_reward\": 68.7166}, {\"step\": 188, \"cum_reward\": 69.1128}, {\"step\": 189, \"cum_reward\": 69.4926}, {\"step\": 190, \"cum_reward\": 69.8924}, {\"step\": 191, \"cum_reward\": 70.295}, {\"step\": 192, \"cum_reward\": 70.6906}, {\"step\": 193, \"cum_reward\": 71.0772}, {\"step\": 194, \"cum_reward\": 71.4904}, {\"step\": 195, \"cum_reward\": 71.8938}, {\"step\": 196, \"cum_reward\": 72.2984}, {\"step\": 197, \"cum_reward\": 72.691}, {\"step\": 198, \"cum_reward\": 73.095}, {\"step\": 199, \"cum_reward\": 73.4852}, {\"step\": 200, \"cum_reward\": 73.8912}, {\"step\": 201, \"cum_reward\": 74.2784}, {\"step\": 202, \"cum_reward\": 74.687}, {\"step\": 203, \"cum_reward\": 75.0894}, {\"step\": 204, \"cum_reward\": 75.478}, {\"step\": 205, \"cum_reward\": 75.8774}, {\"step\": 206, \"cum_reward\": 76.2712}, {\"step\": 207, \"cum_reward\": 76.682}, {\"step\": 208, \"cum_reward\": 77.0836}, {\"step\": 209, \"cum_reward\": 77.4904}, {\"step\": 210, \"cum_reward\": 77.8936}, {\"step\": 211, \"cum_reward\": 78.3034}, {\"step\": 212, \"cum_reward\": 78.6902}, {\"step\": 213, \"cum_reward\": 79.0892}, {\"step\": 214, \"cum_reward\": 79.4732}, {\"step\": 215, \"cum_reward\": 79.8704}, {\"step\": 216, \"cum_reward\": 80.2662}, {\"step\": 217, \"cum_reward\": 80.6604}, {\"step\": 218, \"cum_reward\": 81.0594}, {\"step\": 219, \"cum_reward\": 81.4542}, {\"step\": 220, \"cum_reward\": 81.8548}, {\"step\": 221, \"cum_reward\": 82.2594}, {\"step\": 222, \"cum_reward\": 82.6602}, {\"step\": 223, \"cum_reward\": 83.0556}, {\"step\": 224, \"cum_reward\": 83.4534}, {\"step\": 225, \"cum_reward\": 83.8586}, {\"step\": 226, \"cum_reward\": 84.2604}, {\"step\": 227, \"cum_reward\": 84.6546}, {\"step\": 228, \"cum_reward\": 85.0416}, {\"step\": 229, \"cum_reward\": 85.4272}, {\"step\": 230, \"cum_reward\": 85.8216}, {\"step\": 231, \"cum_reward\": 86.2218}, {\"step\": 232, \"cum_reward\": 86.621}, {\"step\": 233, \"cum_reward\": 87.0294}, {\"step\": 234, \"cum_reward\": 87.4298}, {\"step\": 235, \"cum_reward\": 87.8322}, {\"step\": 236, \"cum_reward\": 88.229}, {\"step\": 237, \"cum_reward\": 88.6224}, {\"step\": 238, \"cum_reward\": 89.0286}, {\"step\": 239, \"cum_reward\": 89.4376}, {\"step\": 240, \"cum_reward\": 89.8454}, {\"step\": 241, \"cum_reward\": 90.2462}, {\"step\": 242, \"cum_reward\": 90.6424}, {\"step\": 243, \"cum_reward\": 91.044}, {\"step\": 244, \"cum_reward\": 91.45}, {\"step\": 245, \"cum_reward\": 91.8614}, {\"step\": 246, \"cum_reward\": 92.2624}, {\"step\": 247, \"cum_reward\": 92.6552}, {\"step\": 248, \"cum_reward\": 93.0524}, {\"step\": 249, \"cum_reward\": 93.4474}, {\"step\": 250, \"cum_reward\": 93.8444}]}}, {\"mode\": \"vega-lite\"});\n",
              "</script>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fsed9Fzq5tra"
      },
      "source": [
        "The cumulative reward plot of the UCB algorithm is comparable to the other algorithms. Although it does not do as well as the best of Epsilon Greedy where the cumulative reward was beyond 105, the UCB cumulative reward range is close to that range (around 100).\n",
        "\n",
        "We also observe some form of curvature in the early phases of the trial, which can be corroborated by the extreme fluctuations we saw in the rate of choosing best arms. Likewise, when the experiment progresses, the algorithm can distinguish the best arm, and picks it with higher frequency, and the cumulative reward plot has a straight line gradient (which should approximate a value of 0.5 based on consistently choosing the best arm)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVdxcCodvStO"
      },
      "source": [
        "df_cumreward[\"best_cumreward\"] = df[\"step\"] * max(means)\n",
        "df_cumreward[\"regret\"] = df_cumreward[\"best_cumreward\"]-  df_cumreward[\"cum_reward\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "3NQ2LIibvZOe",
        "outputId": "c4250396-3177-4053-f6fe-695afadfbf28"
      },
      "source": [
        "\n",
        "alt.Chart(df_cumreward).mark_line().encode(\n",
        "    alt.X(\"step:Q\", title = \"Time Step\"),\n",
        "    alt.Y(\"regret:Q\", title = \"Mean Cumulative Regret\")\n",
        ").properties(\n",
        "    title = \"UCB: Mean Cumulative Regret from 5000 Simulations. 5 Arms = [0.4, 0.3, 0.5, 0.2, 0.1]\",\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "alt.Chart(...)"
            ],
            "text/html": [
              "\n",
              "<div id=\"altair-viz-a86699b626f44ed2af39ab8db1b34264\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "  (function(spec, embedOpt){\n",
              "    let outputDiv = document.currentScript.previousElementSibling;\n",
              "    if (outputDiv.id !== \"altair-viz-a86699b626f44ed2af39ab8db1b34264\") {\n",
              "      outputDiv = document.getElementById(\"altair-viz-a86699b626f44ed2af39ab8db1b34264\");\n",
              "    }\n",
              "    const paths = {\n",
              "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
              "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
              "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
              "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
              "    };\n",
              "\n",
              "    function loadScript(lib) {\n",
              "      return new Promise(function(resolve, reject) {\n",
              "        var s = document.createElement('script');\n",
              "        s.src = paths[lib];\n",
              "        s.async = true;\n",
              "        s.onload = () => resolve(paths[lib]);\n",
              "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
              "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "      });\n",
              "    }\n",
              "\n",
              "    function showError(err) {\n",
              "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
              "      throw err;\n",
              "    }\n",
              "\n",
              "    function displayChart(vegaEmbed) {\n",
              "      vegaEmbed(outputDiv, spec, embedOpt)\n",
              "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
              "    }\n",
              "\n",
              "    if(typeof define === \"function\" && define.amd) {\n",
              "      requirejs.config({paths});\n",
              "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
              "    } else if (typeof vegaEmbed === \"function\") {\n",
              "      displayChart(vegaEmbed);\n",
              "    } else {\n",
              "      loadScript(\"vega\")\n",
              "        .then(() => loadScript(\"vega-lite\"))\n",
              "        .then(() => loadScript(\"vega-embed\"))\n",
              "        .catch(showError)\n",
              "        .then(() => displayChart(vegaEmbed));\n",
              "    }\n",
              "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-0b13019594430520a87ef7bf1df1acbe\"}, \"mark\": \"line\", \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"step\", \"title\": \"Time Step\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"regret\", \"title\": \"Mean Cumulative Regret\"}}, \"title\": \"UCB: Mean Cumulative Regret from 5000 Simulations. 5 Arms = [0.4, 0.3, 0.5, 0.2, 0.1]\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-0b13019594430520a87ef7bf1df1acbe\": [{\"step\": 1, \"cum_reward\": 0.406, \"best_cumreward\": 0.5, \"regret\": 0.09399999999999997}, {\"step\": 2, \"cum_reward\": 0.7076, \"best_cumreward\": 1.0, \"regret\": 0.2924}, {\"step\": 3, \"cum_reward\": 1.1972, \"best_cumreward\": 1.5, \"regret\": 0.30279999999999996}, {\"step\": 4, \"cum_reward\": 1.4126, \"best_cumreward\": 2.0, \"regret\": 0.5873999999999999}, {\"step\": 5, \"cum_reward\": 1.5068, \"best_cumreward\": 2.5, \"regret\": 0.9932000000000001}, {\"step\": 6, \"cum_reward\": 1.8904, \"best_cumreward\": 3.0, \"regret\": 1.1096}, {\"step\": 7, \"cum_reward\": 2.262, \"best_cumreward\": 3.5, \"regret\": 1.238}, {\"step\": 8, \"cum_reward\": 2.6564, \"best_cumreward\": 4.0, \"regret\": 1.3436}, {\"step\": 9, \"cum_reward\": 2.9702, \"best_cumreward\": 4.5, \"regret\": 1.5297999999999998}, {\"step\": 10, \"cum_reward\": 3.1784, \"best_cumreward\": 5.0, \"regret\": 1.8216}, {\"step\": 11, \"cum_reward\": 3.4918, \"best_cumreward\": 5.5, \"regret\": 2.0082}, {\"step\": 12, \"cum_reward\": 3.8224, \"best_cumreward\": 6.0, \"regret\": 2.1776}, {\"step\": 13, \"cum_reward\": 4.182, \"best_cumreward\": 6.5, \"regret\": 2.3179999999999996}, {\"step\": 14, \"cum_reward\": 4.5276, \"best_cumreward\": 7.0, \"regret\": 2.4724000000000004}, {\"step\": 15, \"cum_reward\": 4.8988, \"best_cumreward\": 7.5, \"regret\": 2.6012000000000004}, {\"step\": 16, \"cum_reward\": 5.2598, \"best_cumreward\": 8.0, \"regret\": 2.7401999999999997}, {\"step\": 17, \"cum_reward\": 5.6106, \"best_cumreward\": 8.5, \"regret\": 2.8894}, {\"step\": 18, \"cum_reward\": 5.9336, \"best_cumreward\": 9.0, \"regret\": 3.0664}, {\"step\": 19, \"cum_reward\": 6.238, \"best_cumreward\": 9.5, \"regret\": 3.2619999999999996}, {\"step\": 20, \"cum_reward\": 6.5322, \"best_cumreward\": 10.0, \"regret\": 3.4678000000000004}, {\"step\": 21, \"cum_reward\": 6.8558, \"best_cumreward\": 10.5, \"regret\": 3.6441999999999997}, {\"step\": 22, \"cum_reward\": 7.2108, \"best_cumreward\": 11.0, \"regret\": 3.7892}, {\"step\": 23, \"cum_reward\": 7.5684, \"best_cumreward\": 11.5, \"regret\": 3.9316000000000004}, {\"step\": 24, \"cum_reward\": 7.9332, \"best_cumreward\": 12.0, \"regret\": 4.0668}, {\"step\": 25, \"cum_reward\": 8.3028, \"best_cumreward\": 12.5, \"regret\": 4.1972000000000005}, {\"step\": 26, \"cum_reward\": 8.6636, \"best_cumreward\": 13.0, \"regret\": 4.336399999999999}, {\"step\": 27, \"cum_reward\": 9.0144, \"best_cumreward\": 13.5, \"regret\": 4.4856}, {\"step\": 28, \"cum_reward\": 9.357, \"best_cumreward\": 14.0, \"regret\": 4.643000000000001}, {\"step\": 29, \"cum_reward\": 9.6982, \"best_cumreward\": 14.5, \"regret\": 4.8018}, {\"step\": 30, \"cum_reward\": 10.041, \"best_cumreward\": 15.0, \"regret\": 4.959}, {\"step\": 31, \"cum_reward\": 10.3716, \"best_cumreward\": 15.5, \"regret\": 5.128399999999999}, {\"step\": 32, \"cum_reward\": 10.7074, \"best_cumreward\": 16.0, \"regret\": 5.2926}, {\"step\": 33, \"cum_reward\": 11.0564, \"best_cumreward\": 16.5, \"regret\": 5.4436}, {\"step\": 34, \"cum_reward\": 11.4076, \"best_cumreward\": 17.0, \"regret\": 5.5924}, {\"step\": 35, \"cum_reward\": 11.7526, \"best_cumreward\": 17.5, \"regret\": 5.747400000000001}, {\"step\": 36, \"cum_reward\": 12.1036, \"best_cumreward\": 18.0, \"regret\": 5.8964}, {\"step\": 37, \"cum_reward\": 12.4562, \"best_cumreward\": 18.5, \"regret\": 6.043799999999999}, {\"step\": 38, \"cum_reward\": 12.8026, \"best_cumreward\": 19.0, \"regret\": 6.1974}, {\"step\": 39, \"cum_reward\": 13.1552, \"best_cumreward\": 19.5, \"regret\": 6.344799999999999}, {\"step\": 40, \"cum_reward\": 13.501, \"best_cumreward\": 20.0, \"regret\": 6.4990000000000006}, {\"step\": 41, \"cum_reward\": 13.8616, \"best_cumreward\": 20.5, \"regret\": 6.638400000000001}, {\"step\": 42, \"cum_reward\": 14.2126, \"best_cumreward\": 21.0, \"regret\": 6.7874}, {\"step\": 43, \"cum_reward\": 14.5654, \"best_cumreward\": 21.5, \"regret\": 6.9346}, {\"step\": 44, \"cum_reward\": 14.9154, \"best_cumreward\": 22.0, \"regret\": 7.0846}, {\"step\": 45, \"cum_reward\": 15.2682, \"best_cumreward\": 22.5, \"regret\": 7.2318}, {\"step\": 46, \"cum_reward\": 15.6126, \"best_cumreward\": 23.0, \"regret\": 7.3873999999999995}, {\"step\": 47, \"cum_reward\": 15.9664, \"best_cumreward\": 23.5, \"regret\": 7.5336}, {\"step\": 48, \"cum_reward\": 16.328, \"best_cumreward\": 24.0, \"regret\": 7.672000000000001}, {\"step\": 49, \"cum_reward\": 16.6888, \"best_cumreward\": 24.5, \"regret\": 7.8111999999999995}, {\"step\": 50, \"cum_reward\": 17.0348, \"best_cumreward\": 25.0, \"regret\": 7.965199999999999}, {\"step\": 51, \"cum_reward\": 17.3784, \"best_cumreward\": 25.5, \"regret\": 8.1216}, {\"step\": 52, \"cum_reward\": 17.733, \"best_cumreward\": 26.0, \"regret\": 8.267}, {\"step\": 53, \"cum_reward\": 18.0918, \"best_cumreward\": 26.5, \"regret\": 8.4082}, {\"step\": 54, \"cum_reward\": 18.4388, \"best_cumreward\": 27.0, \"regret\": 8.5612}, {\"step\": 55, \"cum_reward\": 18.7938, \"best_cumreward\": 27.5, \"regret\": 8.706199999999999}, {\"step\": 56, \"cum_reward\": 19.1542, \"best_cumreward\": 28.0, \"regret\": 8.8458}, {\"step\": 57, \"cum_reward\": 19.5148, \"best_cumreward\": 28.5, \"regret\": 8.985199999999999}, {\"step\": 58, \"cum_reward\": 19.875, \"best_cumreward\": 29.0, \"regret\": 9.125}, {\"step\": 59, \"cum_reward\": 20.245, \"best_cumreward\": 29.5, \"regret\": 9.254999999999999}, {\"step\": 60, \"cum_reward\": 20.607, \"best_cumreward\": 30.0, \"regret\": 9.393}, {\"step\": 61, \"cum_reward\": 20.9708, \"best_cumreward\": 30.5, \"regret\": 9.5292}, {\"step\": 62, \"cum_reward\": 21.328, \"best_cumreward\": 31.0, \"regret\": 9.672}, {\"step\": 63, \"cum_reward\": 21.6908, \"best_cumreward\": 31.5, \"regret\": 9.8092}, {\"step\": 64, \"cum_reward\": 22.0556, \"best_cumreward\": 32.0, \"regret\": 9.944400000000002}, {\"step\": 65, \"cum_reward\": 22.4138, \"best_cumreward\": 32.5, \"regret\": 10.086200000000002}, {\"step\": 66, \"cum_reward\": 22.7722, \"best_cumreward\": 33.0, \"regret\": 10.227799999999998}, {\"step\": 67, \"cum_reward\": 23.1452, \"best_cumreward\": 33.5, \"regret\": 10.354800000000001}, {\"step\": 68, \"cum_reward\": 23.5096, \"best_cumreward\": 34.0, \"regret\": 10.490400000000001}, {\"step\": 69, \"cum_reward\": 23.8714, \"best_cumreward\": 34.5, \"regret\": 10.628599999999999}, {\"step\": 70, \"cum_reward\": 24.2264, \"best_cumreward\": 35.0, \"regret\": 10.773599999999998}, {\"step\": 71, \"cum_reward\": 24.5944, \"best_cumreward\": 35.5, \"regret\": 10.9056}, {\"step\": 72, \"cum_reward\": 24.9674, \"best_cumreward\": 36.0, \"regret\": 11.032599999999999}, {\"step\": 73, \"cum_reward\": 25.3232, \"best_cumreward\": 36.5, \"regret\": 11.1768}, {\"step\": 74, \"cum_reward\": 25.684, \"best_cumreward\": 37.0, \"regret\": 11.315999999999999}, {\"step\": 75, \"cum_reward\": 26.0422, \"best_cumreward\": 37.5, \"regret\": 11.457799999999999}, {\"step\": 76, \"cum_reward\": 26.413, \"best_cumreward\": 38.0, \"regret\": 11.587}, {\"step\": 77, \"cum_reward\": 26.7822, \"best_cumreward\": 38.5, \"regret\": 11.7178}, {\"step\": 78, \"cum_reward\": 27.1548, \"best_cumreward\": 39.0, \"regret\": 11.845199999999998}, {\"step\": 79, \"cum_reward\": 27.5246, \"best_cumreward\": 39.5, \"regret\": 11.9754}, {\"step\": 80, \"cum_reward\": 27.8964, \"best_cumreward\": 40.0, \"regret\": 12.1036}, {\"step\": 81, \"cum_reward\": 28.2758, \"best_cumreward\": 40.5, \"regret\": 12.2242}, {\"step\": 82, \"cum_reward\": 28.6312, \"best_cumreward\": 41.0, \"regret\": 12.3688}, {\"step\": 83, \"cum_reward\": 28.9944, \"best_cumreward\": 41.5, \"regret\": 12.505600000000001}, {\"step\": 84, \"cum_reward\": 29.3646, \"best_cumreward\": 42.0, \"regret\": 12.6354}, {\"step\": 85, \"cum_reward\": 29.7454, \"best_cumreward\": 42.5, \"regret\": 12.7546}, {\"step\": 86, \"cum_reward\": 30.121, \"best_cumreward\": 43.0, \"regret\": 12.879000000000001}, {\"step\": 87, \"cum_reward\": 30.4958, \"best_cumreward\": 43.5, \"regret\": 13.0042}, {\"step\": 88, \"cum_reward\": 30.8624, \"best_cumreward\": 44.0, \"regret\": 13.137599999999999}, {\"step\": 89, \"cum_reward\": 31.235, \"best_cumreward\": 44.5, \"regret\": 13.265}, {\"step\": 90, \"cum_reward\": 31.5994, \"best_cumreward\": 45.0, \"regret\": 13.4006}, {\"step\": 91, \"cum_reward\": 31.973, \"best_cumreward\": 45.5, \"regret\": 13.527000000000001}, {\"step\": 92, \"cum_reward\": 32.344, \"best_cumreward\": 46.0, \"regret\": 13.655999999999999}, {\"step\": 93, \"cum_reward\": 32.7092, \"best_cumreward\": 46.5, \"regret\": 13.790799999999997}, {\"step\": 94, \"cum_reward\": 33.0758, \"best_cumreward\": 47.0, \"regret\": 13.924199999999999}, {\"step\": 95, \"cum_reward\": 33.4446, \"best_cumreward\": 47.5, \"regret\": 14.055399999999999}, {\"step\": 96, \"cum_reward\": 33.8164, \"best_cumreward\": 48.0, \"regret\": 14.183599999999998}, {\"step\": 97, \"cum_reward\": 34.1882, \"best_cumreward\": 48.5, \"regret\": 14.311799999999998}, {\"step\": 98, \"cum_reward\": 34.5602, \"best_cumreward\": 49.0, \"regret\": 14.439799999999998}, {\"step\": 99, \"cum_reward\": 34.9238, \"best_cumreward\": 49.5, \"regret\": 14.5762}, {\"step\": 100, \"cum_reward\": 35.2984, \"best_cumreward\": 50.0, \"regret\": 14.7016}, {\"step\": 101, \"cum_reward\": 35.6768, \"best_cumreward\": 50.5, \"regret\": 14.8232}, {\"step\": 102, \"cum_reward\": 36.0448, \"best_cumreward\": 51.0, \"regret\": 14.955199999999998}, {\"step\": 103, \"cum_reward\": 36.4202, \"best_cumreward\": 51.5, \"regret\": 15.079799999999999}, {\"step\": 104, \"cum_reward\": 36.7926, \"best_cumreward\": 52.0, \"regret\": 15.2074}, {\"step\": 105, \"cum_reward\": 37.1692, \"best_cumreward\": 52.5, \"regret\": 15.330800000000004}, {\"step\": 106, \"cum_reward\": 37.5448, \"best_cumreward\": 53.0, \"regret\": 15.455199999999998}, {\"step\": 107, \"cum_reward\": 37.9216, \"best_cumreward\": 53.5, \"regret\": 15.578400000000002}, {\"step\": 108, \"cum_reward\": 38.3048, \"best_cumreward\": 54.0, \"regret\": 15.6952}, {\"step\": 109, \"cum_reward\": 38.6882, \"best_cumreward\": 54.5, \"regret\": 15.811799999999998}, {\"step\": 110, \"cum_reward\": 39.0692, \"best_cumreward\": 55.0, \"regret\": 15.930799999999998}, {\"step\": 111, \"cum_reward\": 39.4492, \"best_cumreward\": 55.5, \"regret\": 16.050800000000002}, {\"step\": 112, \"cum_reward\": 39.8386, \"best_cumreward\": 56.0, \"regret\": 16.1614}, {\"step\": 113, \"cum_reward\": 40.2122, \"best_cumreward\": 56.5, \"regret\": 16.287799999999997}, {\"step\": 114, \"cum_reward\": 40.5864, \"best_cumreward\": 57.0, \"regret\": 16.413600000000002}, {\"step\": 115, \"cum_reward\": 40.9742, \"best_cumreward\": 57.5, \"regret\": 16.525799999999997}, {\"step\": 116, \"cum_reward\": 41.3432, \"best_cumreward\": 58.0, \"regret\": 16.656799999999997}, {\"step\": 117, \"cum_reward\": 41.7224, \"best_cumreward\": 58.5, \"regret\": 16.7776}, {\"step\": 118, \"cum_reward\": 42.096, \"best_cumreward\": 59.0, \"regret\": 16.904000000000003}, {\"step\": 119, \"cum_reward\": 42.4726, \"best_cumreward\": 59.5, \"regret\": 17.0274}, {\"step\": 120, \"cum_reward\": 42.8546, \"best_cumreward\": 60.0, \"regret\": 17.145400000000002}, {\"step\": 121, \"cum_reward\": 43.2248, \"best_cumreward\": 60.5, \"regret\": 17.275199999999998}, {\"step\": 122, \"cum_reward\": 43.6022, \"best_cumreward\": 61.0, \"regret\": 17.397799999999997}, {\"step\": 123, \"cum_reward\": 43.9832, \"best_cumreward\": 61.5, \"regret\": 17.516800000000003}, {\"step\": 124, \"cum_reward\": 44.3632, \"best_cumreward\": 62.0, \"regret\": 17.6368}, {\"step\": 125, \"cum_reward\": 44.736, \"best_cumreward\": 62.5, \"regret\": 17.764000000000003}, {\"step\": 126, \"cum_reward\": 45.1172, \"best_cumreward\": 63.0, \"regret\": 17.882800000000003}, {\"step\": 127, \"cum_reward\": 45.497, \"best_cumreward\": 63.5, \"regret\": 18.003}, {\"step\": 128, \"cum_reward\": 45.8834, \"best_cumreward\": 64.0, \"regret\": 18.1166}, {\"step\": 129, \"cum_reward\": 46.2682, \"best_cumreward\": 64.5, \"regret\": 18.2318}, {\"step\": 130, \"cum_reward\": 46.6466, \"best_cumreward\": 65.0, \"regret\": 18.3534}, {\"step\": 131, \"cum_reward\": 47.0382, \"best_cumreward\": 65.5, \"regret\": 18.461799999999997}, {\"step\": 132, \"cum_reward\": 47.4146, \"best_cumreward\": 66.0, \"regret\": 18.5854}, {\"step\": 133, \"cum_reward\": 47.7914, \"best_cumreward\": 66.5, \"regret\": 18.708599999999997}, {\"step\": 134, \"cum_reward\": 48.175, \"best_cumreward\": 67.0, \"regret\": 18.825000000000003}, {\"step\": 135, \"cum_reward\": 48.5538, \"best_cumreward\": 67.5, \"regret\": 18.946199999999997}, {\"step\": 136, \"cum_reward\": 48.9436, \"best_cumreward\": 68.0, \"regret\": 19.056399999999996}, {\"step\": 137, \"cum_reward\": 49.3318, \"best_cumreward\": 68.5, \"regret\": 19.1682}, {\"step\": 138, \"cum_reward\": 49.7028, \"best_cumreward\": 69.0, \"regret\": 19.297199999999997}, {\"step\": 139, \"cum_reward\": 50.0888, \"best_cumreward\": 69.5, \"regret\": 19.4112}, {\"step\": 140, \"cum_reward\": 50.4858, \"best_cumreward\": 70.0, \"regret\": 19.514200000000002}, {\"step\": 141, \"cum_reward\": 50.8764, \"best_cumreward\": 70.5, \"regret\": 19.623600000000003}, {\"step\": 142, \"cum_reward\": 51.258, \"best_cumreward\": 71.0, \"regret\": 19.741999999999997}, {\"step\": 143, \"cum_reward\": 51.6496, \"best_cumreward\": 71.5, \"regret\": 19.8504}, {\"step\": 144, \"cum_reward\": 52.0296, \"best_cumreward\": 72.0, \"regret\": 19.970399999999998}, {\"step\": 145, \"cum_reward\": 52.4124, \"best_cumreward\": 72.5, \"regret\": 20.087600000000002}, {\"step\": 146, \"cum_reward\": 52.8024, \"best_cumreward\": 73.0, \"regret\": 20.1976}, {\"step\": 147, \"cum_reward\": 53.1842, \"best_cumreward\": 73.5, \"regret\": 20.315800000000003}, {\"step\": 148, \"cum_reward\": 53.5686, \"best_cumreward\": 74.0, \"regret\": 20.431399999999996}, {\"step\": 149, \"cum_reward\": 53.942, \"best_cumreward\": 74.5, \"regret\": 20.558}, {\"step\": 150, \"cum_reward\": 54.316, \"best_cumreward\": 75.0, \"regret\": 20.683999999999997}, {\"step\": 151, \"cum_reward\": 54.706, \"best_cumreward\": 75.5, \"regret\": 20.793999999999997}, {\"step\": 152, \"cum_reward\": 55.089, \"best_cumreward\": 76.0, \"regret\": 20.911}, {\"step\": 153, \"cum_reward\": 55.4762, \"best_cumreward\": 76.5, \"regret\": 21.0238}, {\"step\": 154, \"cum_reward\": 55.8674, \"best_cumreward\": 77.0, \"regret\": 21.132599999999996}, {\"step\": 155, \"cum_reward\": 56.2542, \"best_cumreward\": 77.5, \"regret\": 21.245800000000003}, {\"step\": 156, \"cum_reward\": 56.651, \"best_cumreward\": 78.0, \"regret\": 21.348999999999997}, {\"step\": 157, \"cum_reward\": 57.0414, \"best_cumreward\": 78.5, \"regret\": 21.458599999999997}, {\"step\": 158, \"cum_reward\": 57.4236, \"best_cumreward\": 79.0, \"regret\": 21.5764}, {\"step\": 159, \"cum_reward\": 57.8128, \"best_cumreward\": 79.5, \"regret\": 21.687199999999997}, {\"step\": 160, \"cum_reward\": 58.2, \"best_cumreward\": 80.0, \"regret\": 21.799999999999997}, {\"step\": 161, \"cum_reward\": 58.59, \"best_cumreward\": 80.5, \"regret\": 21.909999999999997}, {\"step\": 162, \"cum_reward\": 58.9724, \"best_cumreward\": 81.0, \"regret\": 22.0276}, {\"step\": 163, \"cum_reward\": 59.3672, \"best_cumreward\": 81.5, \"regret\": 22.132800000000003}, {\"step\": 164, \"cum_reward\": 59.765, \"best_cumreward\": 82.0, \"regret\": 22.235}, {\"step\": 165, \"cum_reward\": 60.1438, \"best_cumreward\": 82.5, \"regret\": 22.3562}, {\"step\": 166, \"cum_reward\": 60.5246, \"best_cumreward\": 83.0, \"regret\": 22.4754}, {\"step\": 167, \"cum_reward\": 60.917, \"best_cumreward\": 83.5, \"regret\": 22.583}, {\"step\": 168, \"cum_reward\": 61.302, \"best_cumreward\": 84.0, \"regret\": 22.698}, {\"step\": 169, \"cum_reward\": 61.6922, \"best_cumreward\": 84.5, \"regret\": 22.8078}, {\"step\": 170, \"cum_reward\": 62.0808, \"best_cumreward\": 85.0, \"regret\": 22.919199999999996}, {\"step\": 171, \"cum_reward\": 62.4678, \"best_cumreward\": 85.5, \"regret\": 23.032200000000003}, {\"step\": 172, \"cum_reward\": 62.8594, \"best_cumreward\": 86.0, \"regret\": 23.1406}, {\"step\": 173, \"cum_reward\": 63.2462, \"best_cumreward\": 86.5, \"regret\": 23.2538}, {\"step\": 174, \"cum_reward\": 63.6412, \"best_cumreward\": 87.0, \"regret\": 23.358800000000002}, {\"step\": 175, \"cum_reward\": 64.0294, \"best_cumreward\": 87.5, \"regret\": 23.470600000000005}, {\"step\": 176, \"cum_reward\": 64.4282, \"best_cumreward\": 88.0, \"regret\": 23.571799999999996}, {\"step\": 177, \"cum_reward\": 64.811, \"best_cumreward\": 88.5, \"regret\": 23.688999999999993}, {\"step\": 178, \"cum_reward\": 65.2026, \"best_cumreward\": 89.0, \"regret\": 23.797399999999996}, {\"step\": 179, \"cum_reward\": 65.5966, \"best_cumreward\": 89.5, \"regret\": 23.903400000000005}, {\"step\": 180, \"cum_reward\": 65.9844, \"best_cumreward\": 90.0, \"regret\": 24.015600000000006}, {\"step\": 181, \"cum_reward\": 66.3786, \"best_cumreward\": 90.5, \"regret\": 24.121399999999994}, {\"step\": 182, \"cum_reward\": 66.7648, \"best_cumreward\": 91.0, \"regret\": 24.235200000000006}, {\"step\": 183, \"cum_reward\": 67.1534, \"best_cumreward\": 91.5, \"regret\": 24.346599999999995}, {\"step\": 184, \"cum_reward\": 67.5518, \"best_cumreward\": 92.0, \"regret\": 24.4482}, {\"step\": 185, \"cum_reward\": 67.9374, \"best_cumreward\": 92.5, \"regret\": 24.562600000000003}, {\"step\": 186, \"cum_reward\": 68.3344, \"best_cumreward\": 93.0, \"regret\": 24.665599999999998}, {\"step\": 187, \"cum_reward\": 68.7166, \"best_cumreward\": 93.5, \"regret\": 24.7834}, {\"step\": 188, \"cum_reward\": 69.1128, \"best_cumreward\": 94.0, \"regret\": 24.887200000000007}, {\"step\": 189, \"cum_reward\": 69.4926, \"best_cumreward\": 94.5, \"regret\": 25.007400000000004}, {\"step\": 190, \"cum_reward\": 69.8924, \"best_cumreward\": 95.0, \"regret\": 25.107600000000005}, {\"step\": 191, \"cum_reward\": 70.295, \"best_cumreward\": 95.5, \"regret\": 25.205}, {\"step\": 192, \"cum_reward\": 70.6906, \"best_cumreward\": 96.0, \"regret\": 25.309399999999997}, {\"step\": 193, \"cum_reward\": 71.0772, \"best_cumreward\": 96.5, \"regret\": 25.422799999999995}, {\"step\": 194, \"cum_reward\": 71.4904, \"best_cumreward\": 97.0, \"regret\": 25.509600000000006}, {\"step\": 195, \"cum_reward\": 71.8938, \"best_cumreward\": 97.5, \"regret\": 25.6062}, {\"step\": 196, \"cum_reward\": 72.2984, \"best_cumreward\": 98.0, \"regret\": 25.7016}, {\"step\": 197, \"cum_reward\": 72.691, \"best_cumreward\": 98.5, \"regret\": 25.808999999999997}, {\"step\": 198, \"cum_reward\": 73.095, \"best_cumreward\": 99.0, \"regret\": 25.905}, {\"step\": 199, \"cum_reward\": 73.4852, \"best_cumreward\": 99.5, \"regret\": 26.014799999999994}, {\"step\": 200, \"cum_reward\": 73.8912, \"best_cumreward\": 100.0, \"regret\": 26.108800000000002}, {\"step\": 201, \"cum_reward\": 74.2784, \"best_cumreward\": 100.5, \"regret\": 26.221599999999995}, {\"step\": 202, \"cum_reward\": 74.687, \"best_cumreward\": 101.0, \"regret\": 26.313000000000002}, {\"step\": 203, \"cum_reward\": 75.0894, \"best_cumreward\": 101.5, \"regret\": 26.410600000000002}, {\"step\": 204, \"cum_reward\": 75.478, \"best_cumreward\": 102.0, \"regret\": 26.522000000000006}, {\"step\": 205, \"cum_reward\": 75.8774, \"best_cumreward\": 102.5, \"regret\": 26.622600000000006}, {\"step\": 206, \"cum_reward\": 76.2712, \"best_cumreward\": 103.0, \"regret\": 26.728800000000007}, {\"step\": 207, \"cum_reward\": 76.682, \"best_cumreward\": 103.5, \"regret\": 26.817999999999998}, {\"step\": 208, \"cum_reward\": 77.0836, \"best_cumreward\": 104.0, \"regret\": 26.916399999999996}, {\"step\": 209, \"cum_reward\": 77.4904, \"best_cumreward\": 104.5, \"regret\": 27.009600000000006}, {\"step\": 210, \"cum_reward\": 77.8936, \"best_cumreward\": 105.0, \"regret\": 27.106399999999994}, {\"step\": 211, \"cum_reward\": 78.3034, \"best_cumreward\": 105.5, \"regret\": 27.196600000000004}, {\"step\": 212, \"cum_reward\": 78.6902, \"best_cumreward\": 106.0, \"regret\": 27.309799999999996}, {\"step\": 213, \"cum_reward\": 79.0892, \"best_cumreward\": 106.5, \"regret\": 27.410799999999995}, {\"step\": 214, \"cum_reward\": 79.4732, \"best_cumreward\": 107.0, \"regret\": 27.526799999999994}, {\"step\": 215, \"cum_reward\": 79.8704, \"best_cumreward\": 107.5, \"regret\": 27.629599999999996}, {\"step\": 216, \"cum_reward\": 80.2662, \"best_cumreward\": 108.0, \"regret\": 27.733800000000002}, {\"step\": 217, \"cum_reward\": 80.6604, \"best_cumreward\": 108.5, \"regret\": 27.839600000000004}, {\"step\": 218, \"cum_reward\": 81.0594, \"best_cumreward\": 109.0, \"regret\": 27.940600000000003}, {\"step\": 219, \"cum_reward\": 81.4542, \"best_cumreward\": 109.5, \"regret\": 28.0458}, {\"step\": 220, \"cum_reward\": 81.8548, \"best_cumreward\": 110.0, \"regret\": 28.145200000000003}, {\"step\": 221, \"cum_reward\": 82.2594, \"best_cumreward\": 110.5, \"regret\": 28.2406}, {\"step\": 222, \"cum_reward\": 82.6602, \"best_cumreward\": 111.0, \"regret\": 28.339799999999997}, {\"step\": 223, \"cum_reward\": 83.0556, \"best_cumreward\": 111.5, \"regret\": 28.4444}, {\"step\": 224, \"cum_reward\": 83.4534, \"best_cumreward\": 112.0, \"regret\": 28.546599999999998}, {\"step\": 225, \"cum_reward\": 83.8586, \"best_cumreward\": 112.5, \"regret\": 28.641400000000004}, {\"step\": 226, \"cum_reward\": 84.2604, \"best_cumreward\": 113.0, \"regret\": 28.739599999999996}, {\"step\": 227, \"cum_reward\": 84.6546, \"best_cumreward\": 113.5, \"regret\": 28.845399999999998}, {\"step\": 228, \"cum_reward\": 85.0416, \"best_cumreward\": 114.0, \"regret\": 28.958399999999997}, {\"step\": 229, \"cum_reward\": 85.4272, \"best_cumreward\": 114.5, \"regret\": 29.0728}, {\"step\": 230, \"cum_reward\": 85.8216, \"best_cumreward\": 115.0, \"regret\": 29.178399999999996}, {\"step\": 231, \"cum_reward\": 86.2218, \"best_cumreward\": 115.5, \"regret\": 29.2782}, {\"step\": 232, \"cum_reward\": 86.621, \"best_cumreward\": 116.0, \"regret\": 29.379000000000005}, {\"step\": 233, \"cum_reward\": 87.0294, \"best_cumreward\": 116.5, \"regret\": 29.470600000000005}, {\"step\": 234, \"cum_reward\": 87.4298, \"best_cumreward\": 117.0, \"regret\": 29.5702}, {\"step\": 235, \"cum_reward\": 87.8322, \"best_cumreward\": 117.5, \"regret\": 29.6678}, {\"step\": 236, \"cum_reward\": 88.229, \"best_cumreward\": 118.0, \"regret\": 29.771}, {\"step\": 237, \"cum_reward\": 88.6224, \"best_cumreward\": 118.5, \"regret\": 29.8776}, {\"step\": 238, \"cum_reward\": 89.0286, \"best_cumreward\": 119.0, \"regret\": 29.971400000000003}, {\"step\": 239, \"cum_reward\": 89.4376, \"best_cumreward\": 119.5, \"regret\": 30.062399999999997}, {\"step\": 240, \"cum_reward\": 89.8454, \"best_cumreward\": 120.0, \"regret\": 30.154600000000002}, {\"step\": 241, \"cum_reward\": 90.2462, \"best_cumreward\": 120.5, \"regret\": 30.2538}, {\"step\": 242, \"cum_reward\": 90.6424, \"best_cumreward\": 121.0, \"regret\": 30.357600000000005}, {\"step\": 243, \"cum_reward\": 91.044, \"best_cumreward\": 121.5, \"regret\": 30.456000000000003}, {\"step\": 244, \"cum_reward\": 91.45, \"best_cumreward\": 122.0, \"regret\": 30.549999999999997}, {\"step\": 245, \"cum_reward\": 91.8614, \"best_cumreward\": 122.5, \"regret\": 30.638599999999997}, {\"step\": 246, \"cum_reward\": 92.2624, \"best_cumreward\": 123.0, \"regret\": 30.7376}, {\"step\": 247, \"cum_reward\": 92.6552, \"best_cumreward\": 123.5, \"regret\": 30.844800000000006}, {\"step\": 248, \"cum_reward\": 93.0524, \"best_cumreward\": 124.0, \"regret\": 30.947599999999994}, {\"step\": 249, \"cum_reward\": 93.4474, \"best_cumreward\": 124.5, \"regret\": 31.052599999999998}, {\"step\": 250, \"cum_reward\": 93.8444, \"best_cumreward\": 125.0, \"regret\": 31.155600000000007}]}}, {\"mode\": \"vega-lite\"});\n",
              "</script>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uW3MmwVfvcTi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOAiFmxi7HEa"
      },
      "source": [
        "Based on the cumulative regret plots, we see that UCB has a cumulative regret of 32. It is also worst off compared to the Epsilon Greedy algorithm which had a range of 21 to 22. The cumulative regret line is also relatively straight, which means that the algorithm will continue to accumulate more regret with a longer time horizon."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpCH-4xa7ofU"
      },
      "source": [
        "##Summary\n",
        "In this analysis of UCB algorithm, a learning takeaway is that for arms with closer means, the UCB algorithm does not seem to be as robust in terms of determining the best arm, for which Epsilon Greedy is more suitable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SGIDP0B7s9Y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}